{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOEf1qpwRcpTlMlUOmDQXbo",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Nas-UoA/Article-Research-pb/blob/main/artlicle_research.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Import TA library\n",
        "\n"
      ],
      "metadata": {
        "id": "kXC0c1-uHCeR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0qRuhbB79aHh",
        "outputId": "daaa5c85-84fd-4f5a-fdfe-ee207940f1de"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: ta in /usr/local/lib/python3.11/dist-packages (0.11.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from ta) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "# prompt: i want to implement python library ta pandas to this colad notebook\n",
        "\n",
        "!pip install ta pandas\n",
        "\n",
        "import ta\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download apple stock close prices from YAHOO Finance API"
      ],
      "metadata": {
        "id": "CXOasfV-HgGe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# download apple stock close prices for the past year, then calculate alla the major technical indicators with ta pandas\n",
        "\n",
        "import yfinance as yf\n",
        "\n",
        "# Download Apple stock data for the past year\n",
        "aapl = yf.Ticker(\"AAPL\")\n",
        "aapl_data = aapl.history(period=\"20y\")\n",
        "\n"
      ],
      "metadata": {
        "id": "ZEkWWQiY_DdC"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Technical Indicators using TA Library"
      ],
      "metadata": {
        "id": "d1c1F8TVfsep"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### All the indicators in ta library"
      ],
      "metadata": {
        "id": "sk28TOHxgV3Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: show me all the indicators in ta library\n",
        "\n",
        "print(\"Volume Indicators:\")\n",
        "print(dir(ta.volume))\n",
        "\n",
        "print(\"\\nVolatility Indicators:\")\n",
        "print(dir(ta.volatility))\n",
        "\n",
        "print(\"\\nTrend Indicators:\")\n",
        "print(dir(ta.trend))\n",
        "\n",
        "print(\"\\nMomentum Indicators:\")\n",
        "print(dir(ta.momentum))\n",
        "\n",
        "print(\"\\nOther Indicators:\")\n",
        "print(dir(ta.others))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ystm9jfqf9zh",
        "outputId": "3b3189c4-9d12-4db6-83e2-681e72ad4794"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Volume Indicators:\n",
            "['AccDistIndexIndicator', 'ChaikinMoneyFlowIndicator', 'EaseOfMovementIndicator', 'ForceIndexIndicator', 'IndicatorMixin', 'MFIIndicator', 'NegativeVolumeIndexIndicator', 'OnBalanceVolumeIndicator', 'VolumePriceTrendIndicator', 'VolumeWeightedAveragePrice', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__spec__', '_ema', 'acc_dist_index', 'chaikin_money_flow', 'ease_of_movement', 'force_index', 'money_flow_index', 'negative_volume_index', 'np', 'on_balance_volume', 'pd', 'sma_ease_of_movement', 'tp', 'volume_price_trend', 'volume_weighted_average_price']\n",
            "\n",
            "Volatility Indicators:\n",
            "['AverageTrueRange', 'BollingerBands', 'DonchianChannel', 'IndicatorMixin', 'KeltnerChannel', 'UlcerIndex', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__spec__', 'average_true_range', 'bollinger_hband', 'bollinger_hband_indicator', 'bollinger_lband', 'bollinger_lband_indicator', 'bollinger_mavg', 'bollinger_pband', 'bollinger_wband', 'donchian_channel_hband', 'donchian_channel_lband', 'donchian_channel_mband', 'donchian_channel_pband', 'donchian_channel_wband', 'keltner_channel_hband', 'keltner_channel_hband_indicator', 'keltner_channel_lband', 'keltner_channel_lband_indicator', 'keltner_channel_mband', 'keltner_channel_pband', 'keltner_channel_wband', 'np', 'pd', 'ulcer_index']\n",
            "\n",
            "Trend Indicators:\n",
            "['ADXIndicator', 'AroonIndicator', 'CCIIndicator', 'DPOIndicator', 'EMAIndicator', 'IchimokuIndicator', 'IndicatorMixin', 'KSTIndicator', 'MACD', 'MassIndex', 'PSARIndicator', 'SMAIndicator', 'STCIndicator', 'TRIXIndicator', 'VortexIndicator', 'WMAIndicator', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__spec__', '_ema', '_get_min_max', '_sma', 'adx', 'adx_neg', 'adx_pos', 'aroon_down', 'aroon_up', 'cci', 'dpo', 'ema_indicator', 'ichimoku_a', 'ichimoku_b', 'ichimoku_base_line', 'ichimoku_conversion_line', 'kst', 'kst_sig', 'macd', 'macd_diff', 'macd_signal', 'mass_index', 'np', 'pd', 'psar_down', 'psar_down_indicator', 'psar_up', 'psar_up_indicator', 'sma_indicator', 'stc', 'trix', 'vortex_indicator_neg', 'vortex_indicator_pos', 'wma_indicator']\n",
            "\n",
            "Momentum Indicators:\n",
            "['AwesomeOscillatorIndicator', 'IndicatorMixin', 'KAMAIndicator', 'PercentagePriceOscillator', 'PercentageVolumeOscillator', 'ROCIndicator', 'RSIIndicator', 'StochRSIIndicator', 'StochasticOscillator', 'TSIIndicator', 'UltimateOscillator', 'WilliamsRIndicator', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__spec__', '_ema', 'awesome_oscillator', 'kama', 'np', 'pd', 'ppo', 'ppo_hist', 'ppo_signal', 'pvo', 'pvo_hist', 'pvo_signal', 'roc', 'rsi', 'stoch', 'stoch_signal', 'stochrsi', 'stochrsi_d', 'stochrsi_k', 'tsi', 'ultimate_oscillator', 'williams_r']\n",
            "\n",
            "Other Indicators:\n",
            "['CumulativeReturnIndicator', 'DailyLogReturnIndicator', 'DailyReturnIndicator', 'IndicatorMixin', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__spec__', 'cumulative_return', 'daily_log_return', 'daily_return', 'np', 'pd']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate technical indicators using ta\n",
        "# Add all technical indicators\n",
        "aapl_ta_data = ta.add_all_ta_features(aapl_data, open=\"Open\", high=\"High\", low=\"Low\", close=\"Close\", volume=\"Volume\")\n",
        "\n",
        "# Display the first few rows with the calculated indicators\n",
        "print(aapl_ta_data.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3g1Q90qYhC3r",
        "outputId": "8f745d18-57da-4c31-eb92-67c49987a5b7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/ta/trend.py:1030: FutureWarning: Series.__setitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To set a value by position, use `ser.iloc[pos] = value`\n",
            "  self._psar[i] = high2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                               Open      High       Low     Close     Volume  \\\n",
            "Date                                                                           \n",
            "2005-08-08 00:00:00-04:00  1.292330  1.299844  1.280609  1.281811  176383200   \n",
            "2005-08-09 00:00:00-04:00  1.290226  1.319078  1.289625  1.316975  380839200   \n",
            "2005-08-10 00:00:00-04:00  1.322384  1.334105  1.301647  1.303751  360945200   \n",
            "2005-08-11 00:00:00-04:00  1.304051  1.325990  1.299844  1.322385  271983600   \n",
            "2005-08-12 00:00:00-04:00  1.306155  1.389104  1.303149  1.385498  916036800   \n",
            "\n",
            "                           Dividends  Stock Splits    volume_adi  volume_obv  \\\n",
            "Date                                                                           \n",
            "2005-08-08 00:00:00-04:00        0.0           0.0 -1.543439e+08   176383200   \n",
            "2005-08-09 00:00:00-04:00        0.0           0.0  1.720910e+08   557222400   \n",
            "2005-08-10 00:00:00-04:00        0.0           0.0 -1.420634e+08   196277200   \n",
            "2005-08-11 00:00:00-04:00        0.0           0.0  5.490193e+07   468260800   \n",
            "2005-08-12 00:00:00-04:00        0.0           0.0  8.940797e+08  1384297600   \n",
            "\n",
            "                           volume_cmf  ...  momentum_ppo  momentum_ppo_signal  \\\n",
            "Date                                   ...                                      \n",
            "2005-08-08 00:00:00-04:00         NaN  ...           NaN                  NaN   \n",
            "2005-08-09 00:00:00-04:00         NaN  ...           NaN                  NaN   \n",
            "2005-08-10 00:00:00-04:00         NaN  ...           NaN                  NaN   \n",
            "2005-08-11 00:00:00-04:00         NaN  ...           NaN                  NaN   \n",
            "2005-08-12 00:00:00-04:00         NaN  ...           NaN                  NaN   \n",
            "\n",
            "                           momentum_ppo_hist  momentum_pvo  \\\n",
            "Date                                                         \n",
            "2005-08-08 00:00:00-04:00                NaN           NaN   \n",
            "2005-08-09 00:00:00-04:00                NaN           NaN   \n",
            "2005-08-10 00:00:00-04:00                NaN           NaN   \n",
            "2005-08-11 00:00:00-04:00                NaN           NaN   \n",
            "2005-08-12 00:00:00-04:00                NaN           NaN   \n",
            "\n",
            "                           momentum_pvo_signal  momentum_pvo_hist  \\\n",
            "Date                                                                \n",
            "2005-08-08 00:00:00-04:00                  NaN                NaN   \n",
            "2005-08-09 00:00:00-04:00                  NaN                NaN   \n",
            "2005-08-10 00:00:00-04:00                  NaN                NaN   \n",
            "2005-08-11 00:00:00-04:00                  NaN                NaN   \n",
            "2005-08-12 00:00:00-04:00                  NaN                NaN   \n",
            "\n",
            "                           momentum_kama  others_dr  others_dlr  others_cr  \n",
            "Date                                                                        \n",
            "2005-08-08 00:00:00-04:00            NaN        NaN         NaN   0.000000  \n",
            "2005-08-09 00:00:00-04:00            NaN   2.743298    2.706343   2.743298  \n",
            "2005-08-10 00:00:00-04:00            NaN  -1.004111   -1.009186   1.711641  \n",
            "2005-08-11 00:00:00-04:00            NaN   1.429258    1.419141   3.165363  \n",
            "2005-08-12 00:00:00-04:00            NaN   4.772691    4.662297   8.089127  \n",
            "\n",
            "[5 rows x 93 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "aapl_ta_data.tail()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        },
        "id": "iuKJOGYF_gqh",
        "outputId": "c4ea825e-5e03-4d61-d441-32fe9e87f8ab"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                 Open        High         Low       Close  \\\n",
              "Date                                                                        \n",
              "2025-07-31 00:00:00-04:00  208.490005  209.839996  207.160004  207.570007   \n",
              "2025-08-01 00:00:00-04:00  210.869995  213.580002  201.500000  202.380005   \n",
              "2025-08-04 00:00:00-04:00  204.509995  207.880005  201.679993  203.350006   \n",
              "2025-08-05 00:00:00-04:00  203.399994  205.339996  202.160004  202.919998   \n",
              "2025-08-06 00:00:00-04:00  205.630005  215.380005  205.589996  213.250000   \n",
              "\n",
              "                              Volume  Dividends  Stock Splits    volume_adi  \\\n",
              "Date                                                                          \n",
              "2025-07-31 00:00:00-04:00   80698400        0.0           0.0  6.712252e+10   \n",
              "2025-08-01 00:00:00-04:00  104434500        0.0           0.0  6.703330e+10   \n",
              "2025-08-04 00:00:00-04:00   75109300        0.0           0.0  6.699866e+10   \n",
              "2025-08-05 00:00:00-04:00   44155100        0.0           0.0  6.697561e+10   \n",
              "2025-08-06 00:00:00-04:00  106498000        0.0           0.0  6.703576e+10   \n",
              "\n",
              "                            volume_obv  volume_cmf  ...  momentum_ppo  \\\n",
              "Date                                                ...                 \n",
              "2025-07-31 00:00:00-04:00  53996789900   -0.196813  ...      0.690173   \n",
              "2025-08-01 00:00:00-04:00  53892355400   -0.280012  ...      0.312297   \n",
              "2025-08-04 00:00:00-04:00  53967464700   -0.273199  ...      0.048428   \n",
              "2025-08-05 00:00:00-04:00  53923309600   -0.297212  ...     -0.176149   \n",
              "2025-08-06 00:00:00-04:00  54029807600   -0.266771  ...      0.045604   \n",
              "\n",
              "                           momentum_ppo_signal  momentum_ppo_hist  \\\n",
              "Date                                                                \n",
              "2025-07-31 00:00:00-04:00             1.024148          -0.333975   \n",
              "2025-08-01 00:00:00-04:00             0.881778          -0.569481   \n",
              "2025-08-04 00:00:00-04:00             0.715108          -0.666679   \n",
              "2025-08-05 00:00:00-04:00             0.536857          -0.713006   \n",
              "2025-08-06 00:00:00-04:00             0.438606          -0.393002   \n",
              "\n",
              "                           momentum_pvo  momentum_pvo_signal  \\\n",
              "Date                                                           \n",
              "2025-07-31 00:00:00-04:00      0.869515            -4.075176   \n",
              "2025-08-01 00:00:00-04:00      8.432587            -1.573623   \n",
              "2025-08-04 00:00:00-04:00      9.790518             0.699205   \n",
              "2025-08-05 00:00:00-04:00      6.652055             1.889775   \n",
              "2025-08-06 00:00:00-04:00     12.119661             3.935752   \n",
              "\n",
              "                           momentum_pvo_hist  momentum_kama  others_dr  \\\n",
              "Date                                                                     \n",
              "2025-07-31 00:00:00-04:00           4.944691     211.420486  -0.707963   \n",
              "2025-08-01 00:00:00-04:00          10.006210     209.977865  -2.500362   \n",
              "2025-08-04 00:00:00-04:00           9.091313     208.811878   0.479297   \n",
              "2025-08-05 00:00:00-04:00           4.762280     206.975525  -0.211462   \n",
              "2025-08-06 00:00:00-04:00           8.183909     207.023040   5.090677   \n",
              "\n",
              "                           others_dlr     others_cr  \n",
              "Date                                                 \n",
              "2025-07-31 00:00:00-04:00   -0.710480  16093.500088  \n",
              "2025-08-01 00:00:00-04:00   -2.532153  15688.603899  \n",
              "2025-08-04 00:00:00-04:00    0.478152  15764.278198  \n",
              "2025-08-05 00:00:00-04:00   -0.211686  15730.731282  \n",
              "2025-08-06 00:00:00-04:00    4.965338  16536.622691  \n",
              "\n",
              "[5 rows x 93 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e8e59ee9-3731-41e3-b9b3-d874592f521a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Open</th>\n",
              "      <th>High</th>\n",
              "      <th>Low</th>\n",
              "      <th>Close</th>\n",
              "      <th>Volume</th>\n",
              "      <th>Dividends</th>\n",
              "      <th>Stock Splits</th>\n",
              "      <th>volume_adi</th>\n",
              "      <th>volume_obv</th>\n",
              "      <th>volume_cmf</th>\n",
              "      <th>...</th>\n",
              "      <th>momentum_ppo</th>\n",
              "      <th>momentum_ppo_signal</th>\n",
              "      <th>momentum_ppo_hist</th>\n",
              "      <th>momentum_pvo</th>\n",
              "      <th>momentum_pvo_signal</th>\n",
              "      <th>momentum_pvo_hist</th>\n",
              "      <th>momentum_kama</th>\n",
              "      <th>others_dr</th>\n",
              "      <th>others_dlr</th>\n",
              "      <th>others_cr</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2025-07-31 00:00:00-04:00</th>\n",
              "      <td>208.490005</td>\n",
              "      <td>209.839996</td>\n",
              "      <td>207.160004</td>\n",
              "      <td>207.570007</td>\n",
              "      <td>80698400</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.712252e+10</td>\n",
              "      <td>53996789900</td>\n",
              "      <td>-0.196813</td>\n",
              "      <td>...</td>\n",
              "      <td>0.690173</td>\n",
              "      <td>1.024148</td>\n",
              "      <td>-0.333975</td>\n",
              "      <td>0.869515</td>\n",
              "      <td>-4.075176</td>\n",
              "      <td>4.944691</td>\n",
              "      <td>211.420486</td>\n",
              "      <td>-0.707963</td>\n",
              "      <td>-0.710480</td>\n",
              "      <td>16093.500088</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-08-01 00:00:00-04:00</th>\n",
              "      <td>210.869995</td>\n",
              "      <td>213.580002</td>\n",
              "      <td>201.500000</td>\n",
              "      <td>202.380005</td>\n",
              "      <td>104434500</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.703330e+10</td>\n",
              "      <td>53892355400</td>\n",
              "      <td>-0.280012</td>\n",
              "      <td>...</td>\n",
              "      <td>0.312297</td>\n",
              "      <td>0.881778</td>\n",
              "      <td>-0.569481</td>\n",
              "      <td>8.432587</td>\n",
              "      <td>-1.573623</td>\n",
              "      <td>10.006210</td>\n",
              "      <td>209.977865</td>\n",
              "      <td>-2.500362</td>\n",
              "      <td>-2.532153</td>\n",
              "      <td>15688.603899</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-08-04 00:00:00-04:00</th>\n",
              "      <td>204.509995</td>\n",
              "      <td>207.880005</td>\n",
              "      <td>201.679993</td>\n",
              "      <td>203.350006</td>\n",
              "      <td>75109300</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.699866e+10</td>\n",
              "      <td>53967464700</td>\n",
              "      <td>-0.273199</td>\n",
              "      <td>...</td>\n",
              "      <td>0.048428</td>\n",
              "      <td>0.715108</td>\n",
              "      <td>-0.666679</td>\n",
              "      <td>9.790518</td>\n",
              "      <td>0.699205</td>\n",
              "      <td>9.091313</td>\n",
              "      <td>208.811878</td>\n",
              "      <td>0.479297</td>\n",
              "      <td>0.478152</td>\n",
              "      <td>15764.278198</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-08-05 00:00:00-04:00</th>\n",
              "      <td>203.399994</td>\n",
              "      <td>205.339996</td>\n",
              "      <td>202.160004</td>\n",
              "      <td>202.919998</td>\n",
              "      <td>44155100</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.697561e+10</td>\n",
              "      <td>53923309600</td>\n",
              "      <td>-0.297212</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.176149</td>\n",
              "      <td>0.536857</td>\n",
              "      <td>-0.713006</td>\n",
              "      <td>6.652055</td>\n",
              "      <td>1.889775</td>\n",
              "      <td>4.762280</td>\n",
              "      <td>206.975525</td>\n",
              "      <td>-0.211462</td>\n",
              "      <td>-0.211686</td>\n",
              "      <td>15730.731282</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-08-06 00:00:00-04:00</th>\n",
              "      <td>205.630005</td>\n",
              "      <td>215.380005</td>\n",
              "      <td>205.589996</td>\n",
              "      <td>213.250000</td>\n",
              "      <td>106498000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>6.703576e+10</td>\n",
              "      <td>54029807600</td>\n",
              "      <td>-0.266771</td>\n",
              "      <td>...</td>\n",
              "      <td>0.045604</td>\n",
              "      <td>0.438606</td>\n",
              "      <td>-0.393002</td>\n",
              "      <td>12.119661</td>\n",
              "      <td>3.935752</td>\n",
              "      <td>8.183909</td>\n",
              "      <td>207.023040</td>\n",
              "      <td>5.090677</td>\n",
              "      <td>4.965338</td>\n",
              "      <td>16536.622691</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 93 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e8e59ee9-3731-41e3-b9b3-d874592f521a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e8e59ee9-3731-41e3-b9b3-d874592f521a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e8e59ee9-3731-41e3-b9b3-d874592f521a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-cc4c7a51-240e-4653-a4a0-b13eab0fa551\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-cc4c7a51-240e-4653-a4a0-b13eab0fa551')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-cc4c7a51-240e-4653-a4a0-b13eab0fa551 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Create a new DataFrame with only the technical indicator columns"
      ],
      "metadata": {
        "id": "GUuCJ8vQoJMz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Identify technical indicator columns by checking for prefixes added by the ta library\n",
        "ta_prefixes = ['volume_', 'volatility_', 'trend_', 'momentum_', 'others_']\n",
        "technical_indicator_cols = [col for col in aapl_ta_data.columns if any(col.startswith(prefix) for prefix in ta_prefixes)]\n",
        "\n",
        "# Create a new DataFrame with only the technical indicator columns\n",
        "aapl_ta_indicators_only = aapl_ta_data[technical_indicator_cols].copy()\n",
        "\n",
        "# Display the first few rows to confirm only technical indicators are present\n",
        "print(aapl_ta_indicators_only.head())\n",
        "print(aapl_ta_indicators_only.tail())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZtAT31jMn3nD",
        "outputId": "42d7f7e6-9a9c-48f5-f298-98e8dc350bac"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                             volume_adi  volume_obv  volume_cmf  volume_fi  \\\n",
            "Date                                                                         \n",
            "2005-08-08 00:00:00-04:00 -1.543439e+08   176383200         NaN        NaN   \n",
            "2005-08-09 00:00:00-04:00  1.720910e+08   557222400         NaN        NaN   \n",
            "2005-08-10 00:00:00-04:00 -1.420634e+08   196277200         NaN        NaN   \n",
            "2005-08-11 00:00:00-04:00  5.490193e+07   468260800         NaN        NaN   \n",
            "2005-08-12 00:00:00-04:00  8.940797e+08  1384297600         NaN        NaN   \n",
            "\n",
            "                           volume_em  volume_sma_em    volume_vpt  \\\n",
            "Date                                                                \n",
            "2005-08-08 00:00:00-04:00        NaN            NaN           NaN   \n",
            "2005-08-09 00:00:00-04:00   0.000109            NaN  1.044755e+07   \n",
            "2005-08-10 00:00:00-04:00   0.000122            NaN  6.823262e+06   \n",
            "2005-08-11 00:00:00-04:00  -0.000048            NaN  1.071061e+07   \n",
            "2005-08-12 00:00:00-04:00   0.000312            NaN  5.443022e+07   \n",
            "\n",
            "                           volume_vwap  volume_mfi   volume_nvi  ...  \\\n",
            "Date                                                             ...   \n",
            "2005-08-08 00:00:00-04:00          NaN         NaN  1000.000000  ...   \n",
            "2005-08-09 00:00:00-04:00          NaN         NaN  1000.000000  ...   \n",
            "2005-08-10 00:00:00-04:00          NaN         NaN   989.958890  ...   \n",
            "2005-08-11 00:00:00-04:00          NaN         NaN  1004.107957  ...   \n",
            "2005-08-12 00:00:00-04:00          NaN         NaN  1004.107957  ...   \n",
            "\n",
            "                           momentum_ppo  momentum_ppo_signal  \\\n",
            "Date                                                           \n",
            "2005-08-08 00:00:00-04:00           NaN                  NaN   \n",
            "2005-08-09 00:00:00-04:00           NaN                  NaN   \n",
            "2005-08-10 00:00:00-04:00           NaN                  NaN   \n",
            "2005-08-11 00:00:00-04:00           NaN                  NaN   \n",
            "2005-08-12 00:00:00-04:00           NaN                  NaN   \n",
            "\n",
            "                           momentum_ppo_hist  momentum_pvo  \\\n",
            "Date                                                         \n",
            "2005-08-08 00:00:00-04:00                NaN           NaN   \n",
            "2005-08-09 00:00:00-04:00                NaN           NaN   \n",
            "2005-08-10 00:00:00-04:00                NaN           NaN   \n",
            "2005-08-11 00:00:00-04:00                NaN           NaN   \n",
            "2005-08-12 00:00:00-04:00                NaN           NaN   \n",
            "\n",
            "                           momentum_pvo_signal  momentum_pvo_hist  \\\n",
            "Date                                                                \n",
            "2005-08-08 00:00:00-04:00                  NaN                NaN   \n",
            "2005-08-09 00:00:00-04:00                  NaN                NaN   \n",
            "2005-08-10 00:00:00-04:00                  NaN                NaN   \n",
            "2005-08-11 00:00:00-04:00                  NaN                NaN   \n",
            "2005-08-12 00:00:00-04:00                  NaN                NaN   \n",
            "\n",
            "                           momentum_kama  others_dr  others_dlr  others_cr  \n",
            "Date                                                                        \n",
            "2005-08-08 00:00:00-04:00            NaN        NaN         NaN   0.000000  \n",
            "2005-08-09 00:00:00-04:00            NaN   2.743298    2.706343   2.743298  \n",
            "2005-08-10 00:00:00-04:00            NaN  -1.004111   -1.009186   1.711641  \n",
            "2005-08-11 00:00:00-04:00            NaN   1.429258    1.419141   3.165363  \n",
            "2005-08-12 00:00:00-04:00            NaN   4.772691    4.662297   8.089127  \n",
            "\n",
            "[5 rows x 86 columns]\n",
            "                             volume_adi   volume_obv  volume_cmf  \\\n",
            "Date                                                               \n",
            "2025-07-31 00:00:00-04:00  6.712252e+10  53996789900   -0.196813   \n",
            "2025-08-01 00:00:00-04:00  6.703330e+10  53892355400   -0.280012   \n",
            "2025-08-04 00:00:00-04:00  6.699866e+10  53967464700   -0.273199   \n",
            "2025-08-05 00:00:00-04:00  6.697561e+10  53923309600   -0.297212   \n",
            "2025-08-06 00:00:00-04:00  6.703576e+10  54029807600   -0.266771   \n",
            "\n",
            "                              volume_fi  volume_em  volume_sma_em  \\\n",
            "Date                                                                \n",
            "2025-07-31 00:00:00-04:00 -3.169364e+07  -5.164154      -1.591949   \n",
            "2025-08-01 00:00:00-04:00 -1.045967e+08 -11.104368      -1.288142   \n",
            "2025-08-04 00:00:00-04:00 -7.924633e+07 -22.782860      -3.507335   \n",
            "2025-08-05 00:00:00-04:00 -7.063786e+07  -7.417917      -4.102220   \n",
            "2025-08-06 00:00:00-04:00  9.661391e+07  61.912631       0.262639   \n",
            "\n",
            "                             volume_vpt  volume_vwap  volume_mfi  \\\n",
            "Date                                                               \n",
            "2025-07-31 00:00:00-04:00  1.873894e+09   211.570290   56.332297   \n",
            "2025-08-01 00:00:00-04:00  1.871282e+09   210.890432   51.489554   \n",
            "2025-08-04 00:00:00-04:00  1.871642e+09   210.298749   43.955712   \n",
            "2025-08-05 00:00:00-04:00  1.871549e+09   209.899698   38.026540   \n",
            "2025-08-06 00:00:00-04:00  1.876970e+09   210.060863   42.456142   \n",
            "\n",
            "                              volume_nvi  ...  momentum_ppo  \\\n",
            "Date                                      ...                 \n",
            "2025-07-31 00:00:00-04:00  135376.179772  ...      0.690173   \n",
            "2025-08-01 00:00:00-04:00  135376.179772  ...      0.312297   \n",
            "2025-08-04 00:00:00-04:00  136025.033693  ...      0.048428   \n",
            "2025-08-05 00:00:00-04:00  135737.392473  ...     -0.176149   \n",
            "2025-08-06 00:00:00-04:00  135737.392473  ...      0.045604   \n",
            "\n",
            "                           momentum_ppo_signal  momentum_ppo_hist  \\\n",
            "Date                                                                \n",
            "2025-07-31 00:00:00-04:00             1.024148          -0.333975   \n",
            "2025-08-01 00:00:00-04:00             0.881778          -0.569481   \n",
            "2025-08-04 00:00:00-04:00             0.715108          -0.666679   \n",
            "2025-08-05 00:00:00-04:00             0.536857          -0.713006   \n",
            "2025-08-06 00:00:00-04:00             0.438606          -0.393002   \n",
            "\n",
            "                           momentum_pvo  momentum_pvo_signal  \\\n",
            "Date                                                           \n",
            "2025-07-31 00:00:00-04:00      0.869515            -4.075176   \n",
            "2025-08-01 00:00:00-04:00      8.432587            -1.573623   \n",
            "2025-08-04 00:00:00-04:00      9.790518             0.699205   \n",
            "2025-08-05 00:00:00-04:00      6.652055             1.889775   \n",
            "2025-08-06 00:00:00-04:00     12.119661             3.935752   \n",
            "\n",
            "                           momentum_pvo_hist  momentum_kama  others_dr  \\\n",
            "Date                                                                     \n",
            "2025-07-31 00:00:00-04:00           4.944691     211.420486  -0.707963   \n",
            "2025-08-01 00:00:00-04:00          10.006210     209.977865  -2.500362   \n",
            "2025-08-04 00:00:00-04:00           9.091313     208.811878   0.479297   \n",
            "2025-08-05 00:00:00-04:00           4.762280     206.975525  -0.211462   \n",
            "2025-08-06 00:00:00-04:00           8.183909     207.023040   5.090677   \n",
            "\n",
            "                           others_dlr     others_cr  \n",
            "Date                                                 \n",
            "2025-07-31 00:00:00-04:00   -0.710480  16093.500088  \n",
            "2025-08-01 00:00:00-04:00   -2.532153  15688.603899  \n",
            "2025-08-04 00:00:00-04:00    0.478152  15764.278198  \n",
            "2025-08-05 00:00:00-04:00   -0.211686  15730.731282  \n",
            "2025-08-06 00:00:00-04:00    4.965338  16536.622691  \n",
            "\n",
            "[5 rows x 86 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09244112"
      },
      "source": [
        "### Creating a price trend boolean feature for clasiffication models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dab2d9c0",
        "outputId": "e9fcce1e-08d2-4f8b-f489-5b09902b7170"
      },
      "source": [
        "# Create a new DataFrame and copy necessary columns from aapl_data\n",
        "aapl_data_price_trend = aapl_data[['Close']].copy()\n",
        "\n",
        "# Create the 'price_trend' feature in the new DataFrame\n",
        "aapl_data_price_trend['price_trend'] = aapl_data_price_trend['Close'].diff().apply(lambda x: 'up' if x > 0 else 'down')\n",
        "\n",
        "# Display the first few rows to show the new DataFrame and feature\n",
        "print(aapl_data_price_trend.head())\n",
        "print(aapl_data_price_trend.tail())"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                              Close price_trend\n",
            "Date                                           \n",
            "2005-08-08 00:00:00-04:00  1.281811        down\n",
            "2005-08-09 00:00:00-04:00  1.316975          up\n",
            "2005-08-10 00:00:00-04:00  1.303751        down\n",
            "2005-08-11 00:00:00-04:00  1.322385          up\n",
            "2005-08-12 00:00:00-04:00  1.385498          up\n",
            "                                Close price_trend\n",
            "Date                                             \n",
            "2025-07-31 00:00:00-04:00  207.570007        down\n",
            "2025-08-01 00:00:00-04:00  202.380005        down\n",
            "2025-08-04 00:00:00-04:00  203.350006          up\n",
            "2025-08-05 00:00:00-04:00  202.919998        down\n",
            "2025-08-06 00:00:00-04:00  213.250000          up\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Selecting only trend indicators from TA Library"
      ],
      "metadata": {
        "id": "vTi2_j4wJIPP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: calculate the dir(ta.trend) on apple stock\n",
        "\n",
        "print(dir(ta.trend))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_w03prdAtRw",
        "outputId": "1ea0bfbc-594a-472d-f68a-1cb8a668dafc"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['ADXIndicator', 'AroonIndicator', 'CCIIndicator', 'DPOIndicator', 'EMAIndicator', 'IchimokuIndicator', 'IndicatorMixin', 'KSTIndicator', 'MACD', 'MassIndex', 'PSARIndicator', 'SMAIndicator', 'STCIndicator', 'TRIXIndicator', 'VortexIndicator', 'WMAIndicator', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__spec__', '__warningregistry__', '_ema', '_get_min_max', '_sma', 'adx', 'adx_neg', 'adx_pos', 'aroon_down', 'aroon_up', 'cci', 'dpo', 'ema_indicator', 'ichimoku_a', 'ichimoku_b', 'ichimoku_base_line', 'ichimoku_conversion_line', 'kst', 'kst_sig', 'macd', 'macd_diff', 'macd_signal', 'mass_index', 'np', 'pd', 'psar_down', 'psar_down_indicator', 'psar_up', 'psar_up_indicator', 'sma_indicator', 'stc', 'trix', 'vortex_indicator_neg', 'vortex_indicator_pos', 'wma_indicator']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: calculate the trend technical analysis indicators on apple stock using ta pandas\n",
        "\n",
        "# Select only the trend indicators\n",
        "trend_indicators = aapl_data[['trend_macd', 'trend_macd_signal', 'trend_macd_diff', 'trend_sma_fast', 'trend_sma_slow', 'trend_ema_fast', 'trend_ema_slow', 'trend_adx', 'trend_adx_pos', 'trend_adx_neg', 'trend_vortex_ind_pos', 'trend_vortex_ind_neg', 'trend_vortex_ind_diff', 'trend_trix', 'trend_mass_index', 'trend_dpo', 'trend_kst', 'trend_kst_sig', 'trend_ichimoku_conv', 'trend_ichimoku_base', 'trend_ichimoku_a', 'trend_ichimoku_b', 'trend_cci', 'trend_aroon_up', 'trend_aroon_down', 'trend_aroon_ind']]\n",
        "\n",
        "# Display the first few rows with only the trend indicators\n",
        "print(trend_indicators.head())\n",
        "trend_indicators.tail()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "eyVV7XgLBB3p",
        "outputId": "ba8d26e1-a69a-4ff9-a904-2e3598836eef"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                           trend_macd  trend_macd_signal  trend_macd_diff  \\\n",
            "Date                                                                        \n",
            "2005-08-08 00:00:00-04:00         NaN                NaN              NaN   \n",
            "2005-08-09 00:00:00-04:00         NaN                NaN              NaN   \n",
            "2005-08-10 00:00:00-04:00         NaN                NaN              NaN   \n",
            "2005-08-11 00:00:00-04:00         NaN                NaN              NaN   \n",
            "2005-08-12 00:00:00-04:00         NaN                NaN              NaN   \n",
            "\n",
            "                           trend_sma_fast  trend_sma_slow  trend_ema_fast  \\\n",
            "Date                                                                        \n",
            "2005-08-08 00:00:00-04:00             NaN             NaN             NaN   \n",
            "2005-08-09 00:00:00-04:00             NaN             NaN             NaN   \n",
            "2005-08-10 00:00:00-04:00             NaN             NaN             NaN   \n",
            "2005-08-11 00:00:00-04:00             NaN             NaN             NaN   \n",
            "2005-08-12 00:00:00-04:00             NaN             NaN             NaN   \n",
            "\n",
            "                           trend_ema_slow  trend_adx  trend_adx_pos  \\\n",
            "Date                                                                  \n",
            "2005-08-08 00:00:00-04:00             NaN        0.0            0.0   \n",
            "2005-08-09 00:00:00-04:00             NaN        0.0            0.0   \n",
            "2005-08-10 00:00:00-04:00             NaN        0.0            0.0   \n",
            "2005-08-11 00:00:00-04:00             NaN        0.0            0.0   \n",
            "2005-08-12 00:00:00-04:00             NaN        0.0            0.0   \n",
            "\n",
            "                           trend_adx_neg  ...  trend_kst  trend_kst_sig  \\\n",
            "Date                                      ...                             \n",
            "2005-08-08 00:00:00-04:00            0.0  ...        NaN            NaN   \n",
            "2005-08-09 00:00:00-04:00            0.0  ...        NaN            NaN   \n",
            "2005-08-10 00:00:00-04:00            0.0  ...        NaN            NaN   \n",
            "2005-08-11 00:00:00-04:00            0.0  ...        NaN            NaN   \n",
            "2005-08-12 00:00:00-04:00            0.0  ...        NaN            NaN   \n",
            "\n",
            "                           trend_ichimoku_conv  trend_ichimoku_base  \\\n",
            "Date                                                                  \n",
            "2005-08-08 00:00:00-04:00                  NaN                  NaN   \n",
            "2005-08-09 00:00:00-04:00                  NaN                  NaN   \n",
            "2005-08-10 00:00:00-04:00                  NaN                  NaN   \n",
            "2005-08-11 00:00:00-04:00                  NaN                  NaN   \n",
            "2005-08-12 00:00:00-04:00                  NaN                  NaN   \n",
            "\n",
            "                           trend_ichimoku_a  trend_ichimoku_b  trend_cci  \\\n",
            "Date                                                                       \n",
            "2005-08-08 00:00:00-04:00               NaN          1.290226        NaN   \n",
            "2005-08-09 00:00:00-04:00               NaN          1.299844        NaN   \n",
            "2005-08-10 00:00:00-04:00               NaN          1.307357        NaN   \n",
            "2005-08-11 00:00:00-04:00               NaN          1.307357        NaN   \n",
            "2005-08-12 00:00:00-04:00               NaN          1.334856        NaN   \n",
            "\n",
            "                           trend_aroon_up  trend_aroon_down  trend_aroon_ind  \n",
            "Date                                                                          \n",
            "2005-08-08 00:00:00-04:00             NaN               NaN              NaN  \n",
            "2005-08-09 00:00:00-04:00             NaN               NaN              NaN  \n",
            "2005-08-10 00:00:00-04:00             NaN               NaN              NaN  \n",
            "2005-08-11 00:00:00-04:00             NaN               NaN              NaN  \n",
            "2005-08-12 00:00:00-04:00             NaN               NaN              NaN  \n",
            "\n",
            "[5 rows x 26 columns]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                           trend_macd  trend_macd_signal  trend_macd_diff  \\\n",
              "Date                                                                        \n",
              "2025-07-31 00:00:00-04:00    1.446170           2.139339        -0.693169   \n",
              "2025-08-01 00:00:00-04:00    0.652723           1.842016        -1.189293   \n",
              "2025-08-04 00:00:00-04:00    0.101016           1.493816        -1.392800   \n",
              "2025-08-05 00:00:00-04:00   -0.366686           1.121715        -1.488402   \n",
              "2025-08-06 00:00:00-04:00    0.095104           0.916393        -0.821289   \n",
              "\n",
              "                           trend_sma_fast  trend_sma_slow  trend_ema_fast  \\\n",
              "Date                                                                        \n",
              "2025-07-31 00:00:00-04:00      211.830833      209.884231      210.983567   \n",
              "2025-08-01 00:00:00-04:00      211.182500      209.915770      209.659942   \n",
              "2025-08-04 00:00:00-04:00      210.626667      210.006155      208.689182   \n",
              "2025-08-05 00:00:00-04:00      209.938334      210.076924      207.801616   \n",
              "2025-08-06 00:00:00-04:00      210.002501      210.387693      208.639829   \n",
              "\n",
              "                           trend_ema_slow  trend_adx  trend_adx_pos  \\\n",
              "Date                                                                  \n",
              "2025-07-31 00:00:00-04:00      209.537396  18.505681      17.292701   \n",
              "2025-08-01 00:00:00-04:00      209.007219  19.447271      13.637914   \n",
              "2025-08-04 00:00:00-04:00      208.588166  20.321605      12.211403   \n",
              "2025-08-05 00:00:00-04:00      208.168302  21.133487      11.544416   \n",
              "2025-08-06 00:00:00-04:00      208.544724  20.696144      24.474894   \n",
              "\n",
              "                           trend_adx_neg  ...  trend_kst  trend_kst_sig  \\\n",
              "Date                                      ...                             \n",
              "2025-07-31 00:00:00-04:00      20.779486  ...  40.358010      46.855491   \n",
              "2025-08-01 00:00:00-04:00      26.290366  ...  33.768256      45.575436   \n",
              "2025-08-04 00:00:00-04:00      23.540423  ...  28.077938      43.386117   \n",
              "2025-08-05 00:00:00-04:00      22.254644  ...  21.999527      40.335293   \n",
              "2025-08-06 00:00:00-04:00      18.086185  ...  20.330824      37.176731   \n",
              "\n",
              "                           trend_ichimoku_conv  trend_ichimoku_base  \\\n",
              "Date                                                                  \n",
              "2025-07-31 00:00:00-04:00           211.470001           207.744995   \n",
              "2025-08-01 00:00:00-04:00           208.595001           207.744995   \n",
              "2025-08-04 00:00:00-04:00           208.595001           207.744995   \n",
              "2025-08-05 00:00:00-04:00           208.595001           207.744995   \n",
              "2025-08-06 00:00:00-04:00           208.440002           208.864998   \n",
              "\n",
              "                           trend_ichimoku_a  trend_ichimoku_b   trend_cci  \\\n",
              "Date                                                                        \n",
              "2025-07-31 00:00:00-04:00        209.607498        204.845001 -137.571743   \n",
              "2025-08-01 00:00:00-04:00        208.169998        204.845001 -197.746148   \n",
              "2025-08-04 00:00:00-04:00        208.169998        204.845001 -208.656062   \n",
              "2025-08-05 00:00:00-04:00        208.169998        204.845001 -194.628958   \n",
              "2025-08-06 00:00:00-04:00        208.652500        204.845001   21.416783   \n",
              "\n",
              "                           trend_aroon_up  trend_aroon_down  trend_aroon_ind  \n",
              "Date                                                                          \n",
              "2025-07-31 00:00:00-04:00            28.0              12.0             16.0  \n",
              "2025-08-01 00:00:00-04:00            24.0               8.0             16.0  \n",
              "2025-08-04 00:00:00-04:00            20.0               4.0             16.0  \n",
              "2025-08-05 00:00:00-04:00            16.0               0.0             16.0  \n",
              "2025-08-06 00:00:00-04:00            12.0              88.0            -76.0  \n",
              "\n",
              "[5 rows x 26 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a46493d6-29e1-4b69-b775-20b0808d98c2\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>trend_macd</th>\n",
              "      <th>trend_macd_signal</th>\n",
              "      <th>trend_macd_diff</th>\n",
              "      <th>trend_sma_fast</th>\n",
              "      <th>trend_sma_slow</th>\n",
              "      <th>trend_ema_fast</th>\n",
              "      <th>trend_ema_slow</th>\n",
              "      <th>trend_adx</th>\n",
              "      <th>trend_adx_pos</th>\n",
              "      <th>trend_adx_neg</th>\n",
              "      <th>...</th>\n",
              "      <th>trend_kst</th>\n",
              "      <th>trend_kst_sig</th>\n",
              "      <th>trend_ichimoku_conv</th>\n",
              "      <th>trend_ichimoku_base</th>\n",
              "      <th>trend_ichimoku_a</th>\n",
              "      <th>trend_ichimoku_b</th>\n",
              "      <th>trend_cci</th>\n",
              "      <th>trend_aroon_up</th>\n",
              "      <th>trend_aroon_down</th>\n",
              "      <th>trend_aroon_ind</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Date</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2025-07-31 00:00:00-04:00</th>\n",
              "      <td>1.446170</td>\n",
              "      <td>2.139339</td>\n",
              "      <td>-0.693169</td>\n",
              "      <td>211.830833</td>\n",
              "      <td>209.884231</td>\n",
              "      <td>210.983567</td>\n",
              "      <td>209.537396</td>\n",
              "      <td>18.505681</td>\n",
              "      <td>17.292701</td>\n",
              "      <td>20.779486</td>\n",
              "      <td>...</td>\n",
              "      <td>40.358010</td>\n",
              "      <td>46.855491</td>\n",
              "      <td>211.470001</td>\n",
              "      <td>207.744995</td>\n",
              "      <td>209.607498</td>\n",
              "      <td>204.845001</td>\n",
              "      <td>-137.571743</td>\n",
              "      <td>28.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>16.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-08-01 00:00:00-04:00</th>\n",
              "      <td>0.652723</td>\n",
              "      <td>1.842016</td>\n",
              "      <td>-1.189293</td>\n",
              "      <td>211.182500</td>\n",
              "      <td>209.915770</td>\n",
              "      <td>209.659942</td>\n",
              "      <td>209.007219</td>\n",
              "      <td>19.447271</td>\n",
              "      <td>13.637914</td>\n",
              "      <td>26.290366</td>\n",
              "      <td>...</td>\n",
              "      <td>33.768256</td>\n",
              "      <td>45.575436</td>\n",
              "      <td>208.595001</td>\n",
              "      <td>207.744995</td>\n",
              "      <td>208.169998</td>\n",
              "      <td>204.845001</td>\n",
              "      <td>-197.746148</td>\n",
              "      <td>24.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>16.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-08-04 00:00:00-04:00</th>\n",
              "      <td>0.101016</td>\n",
              "      <td>1.493816</td>\n",
              "      <td>-1.392800</td>\n",
              "      <td>210.626667</td>\n",
              "      <td>210.006155</td>\n",
              "      <td>208.689182</td>\n",
              "      <td>208.588166</td>\n",
              "      <td>20.321605</td>\n",
              "      <td>12.211403</td>\n",
              "      <td>23.540423</td>\n",
              "      <td>...</td>\n",
              "      <td>28.077938</td>\n",
              "      <td>43.386117</td>\n",
              "      <td>208.595001</td>\n",
              "      <td>207.744995</td>\n",
              "      <td>208.169998</td>\n",
              "      <td>204.845001</td>\n",
              "      <td>-208.656062</td>\n",
              "      <td>20.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>16.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-08-05 00:00:00-04:00</th>\n",
              "      <td>-0.366686</td>\n",
              "      <td>1.121715</td>\n",
              "      <td>-1.488402</td>\n",
              "      <td>209.938334</td>\n",
              "      <td>210.076924</td>\n",
              "      <td>207.801616</td>\n",
              "      <td>208.168302</td>\n",
              "      <td>21.133487</td>\n",
              "      <td>11.544416</td>\n",
              "      <td>22.254644</td>\n",
              "      <td>...</td>\n",
              "      <td>21.999527</td>\n",
              "      <td>40.335293</td>\n",
              "      <td>208.595001</td>\n",
              "      <td>207.744995</td>\n",
              "      <td>208.169998</td>\n",
              "      <td>204.845001</td>\n",
              "      <td>-194.628958</td>\n",
              "      <td>16.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>16.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2025-08-06 00:00:00-04:00</th>\n",
              "      <td>0.095104</td>\n",
              "      <td>0.916393</td>\n",
              "      <td>-0.821289</td>\n",
              "      <td>210.002501</td>\n",
              "      <td>210.387693</td>\n",
              "      <td>208.639829</td>\n",
              "      <td>208.544724</td>\n",
              "      <td>20.696144</td>\n",
              "      <td>24.474894</td>\n",
              "      <td>18.086185</td>\n",
              "      <td>...</td>\n",
              "      <td>20.330824</td>\n",
              "      <td>37.176731</td>\n",
              "      <td>208.440002</td>\n",
              "      <td>208.864998</td>\n",
              "      <td>208.652500</td>\n",
              "      <td>204.845001</td>\n",
              "      <td>21.416783</td>\n",
              "      <td>12.0</td>\n",
              "      <td>88.0</td>\n",
              "      <td>-76.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 26 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a46493d6-29e1-4b69-b775-20b0808d98c2')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a46493d6-29e1-4b69-b775-20b0808d98c2 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a46493d6-29e1-4b69-b775-20b0808d98c2');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-0792a7ef-f24a-4ae3-8984-8c4ac4c645a1\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0792a7ef-f24a-4ae3-8984-8c4ac4c645a1')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-0792a7ef-f24a-4ae3-8984-8c4ac4c645a1 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Normalizing the data"
      ],
      "metadata": {
        "id": "v74lYFSNJX_c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: normalize all the trend_indicators df and the apple close price\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Initialize the MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "# Normalize the trend_indicators DataFrame\n",
        "aapl_ta_indicators_only_normalized = pd.DataFrame(scaler.fit_transform(aapl_ta_indicators_only), columns=aapl_ta_indicators_only.columns, index=trend_indicators.index)\n",
        "\n",
        "# Normalize the 'Close' price column from the original DataFrame\n",
        "aapl_close_normalized = aapl_data[['Close']].copy()\n",
        "aapl_close_normalized['Close'] = scaler.fit_transform(aapl_data[['Close']])\n",
        "\n",
        "# Display the first few rows of the normalized trend indicators\n",
        "print(\"Normalized Trend Indicators:\")\n",
        "print(aapl_ta_indicators_only.head())\n",
        "\n",
        "# Display the first few rows of the normalized Apple Close price\n",
        "print(\"\\nNormalized Apple Close Price:\")\n",
        "print(aapl_close_normalized.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oyaNJNfRAtnY",
        "outputId": "7b041241-2098-4df1-a90f-415e1a726fac"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Normalized Trend Indicators:\n",
            "                             volume_adi  volume_obv  volume_cmf  volume_fi  \\\n",
            "Date                                                                         \n",
            "2005-08-08 00:00:00-04:00 -1.543439e+08   176383200         NaN        NaN   \n",
            "2005-08-09 00:00:00-04:00  1.720910e+08   557222400         NaN        NaN   \n",
            "2005-08-10 00:00:00-04:00 -1.420634e+08   196277200         NaN        NaN   \n",
            "2005-08-11 00:00:00-04:00  5.490193e+07   468260800         NaN        NaN   \n",
            "2005-08-12 00:00:00-04:00  8.940797e+08  1384297600         NaN        NaN   \n",
            "\n",
            "                           volume_em  volume_sma_em    volume_vpt  \\\n",
            "Date                                                                \n",
            "2005-08-08 00:00:00-04:00        NaN            NaN           NaN   \n",
            "2005-08-09 00:00:00-04:00   0.000109            NaN  1.044755e+07   \n",
            "2005-08-10 00:00:00-04:00   0.000122            NaN  6.823262e+06   \n",
            "2005-08-11 00:00:00-04:00  -0.000048            NaN  1.071061e+07   \n",
            "2005-08-12 00:00:00-04:00   0.000312            NaN  5.443022e+07   \n",
            "\n",
            "                           volume_vwap  volume_mfi   volume_nvi  ...  \\\n",
            "Date                                                             ...   \n",
            "2005-08-08 00:00:00-04:00          NaN         NaN  1000.000000  ...   \n",
            "2005-08-09 00:00:00-04:00          NaN         NaN  1000.000000  ...   \n",
            "2005-08-10 00:00:00-04:00          NaN         NaN   989.958890  ...   \n",
            "2005-08-11 00:00:00-04:00          NaN         NaN  1004.107957  ...   \n",
            "2005-08-12 00:00:00-04:00          NaN         NaN  1004.107957  ...   \n",
            "\n",
            "                           momentum_ppo  momentum_ppo_signal  \\\n",
            "Date                                                           \n",
            "2005-08-08 00:00:00-04:00           NaN                  NaN   \n",
            "2005-08-09 00:00:00-04:00           NaN                  NaN   \n",
            "2005-08-10 00:00:00-04:00           NaN                  NaN   \n",
            "2005-08-11 00:00:00-04:00           NaN                  NaN   \n",
            "2005-08-12 00:00:00-04:00           NaN                  NaN   \n",
            "\n",
            "                           momentum_ppo_hist  momentum_pvo  \\\n",
            "Date                                                         \n",
            "2005-08-08 00:00:00-04:00                NaN           NaN   \n",
            "2005-08-09 00:00:00-04:00                NaN           NaN   \n",
            "2005-08-10 00:00:00-04:00                NaN           NaN   \n",
            "2005-08-11 00:00:00-04:00                NaN           NaN   \n",
            "2005-08-12 00:00:00-04:00                NaN           NaN   \n",
            "\n",
            "                           momentum_pvo_signal  momentum_pvo_hist  \\\n",
            "Date                                                                \n",
            "2005-08-08 00:00:00-04:00                  NaN                NaN   \n",
            "2005-08-09 00:00:00-04:00                  NaN                NaN   \n",
            "2005-08-10 00:00:00-04:00                  NaN                NaN   \n",
            "2005-08-11 00:00:00-04:00                  NaN                NaN   \n",
            "2005-08-12 00:00:00-04:00                  NaN                NaN   \n",
            "\n",
            "                           momentum_kama  others_dr  others_dlr  others_cr  \n",
            "Date                                                                        \n",
            "2005-08-08 00:00:00-04:00            NaN        NaN         NaN   0.000000  \n",
            "2005-08-09 00:00:00-04:00            NaN   2.743298    2.706343   2.743298  \n",
            "2005-08-10 00:00:00-04:00            NaN  -1.004111   -1.009186   1.711641  \n",
            "2005-08-11 00:00:00-04:00            NaN   1.429258    1.419141   3.165363  \n",
            "2005-08-12 00:00:00-04:00            NaN   4.772691    4.662297   8.089127  \n",
            "\n",
            "[5 rows x 86 columns]\n",
            "\n",
            "Normalized Apple Close Price:\n",
            "                              Close\n",
            "Date                               \n",
            "2005-08-08 00:00:00-04:00  0.000000\n",
            "2005-08-09 00:00:00-04:00  0.000137\n",
            "2005-08-10 00:00:00-04:00  0.000085\n",
            "2005-08-11 00:00:00-04:00  0.000158\n",
            "2005-08-12 00:00:00-04:00  0.000403\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Creating a CNN regression with depended variable the normalized apple close price and all the technical indicators"
      ],
      "metadata": {
        "id": "SgjQp-3KJhhq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: i want to run a convolutional deep neurak network regression with depended variable the normalized apple close price and as indepented features all the technical indicators\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Reshape features for CNN (samples, timesteps, features)\n",
        "# For a 1D CNN, timesteps can be 1 if each data point is treated independently.\n",
        "# If you want to consider sequences of data, you would need to structure your data differently.\n",
        "# For simplicity, we'll treat each row as a single timestep for now.\n",
        "X_cnn = X_scaled.reshape(X_scaled.shape[0], X_scaled.shape[1], 1) # Reshape to (samples, features, 1)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train_cnn, X_test_cnn, y_train_cnn, y_test_cnn = train_test_split(X_cnn, y_scaled, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the CNN model\n",
        "model_cnn = Sequential([\n",
        "    Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(X_train_cnn.shape[1], 1)),\n",
        "    MaxPooling1D(pool_size=2),\n",
        "    Conv1D(filters=64, kernel_size=3, activation='relu'),\n",
        "    MaxPooling1D(pool_size=2),\n",
        "    Flatten(),\n",
        "    Dense(50, activation='relu'),\n",
        "    Dense(1) # Output layer for regression\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model_cnn.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# Train the model\n",
        "history_cnn = model_cnn.fit(X_train_cnn, y_train_cnn, epochs=50, batch_size=32, validation_split=0.2, verbose=0)\n",
        "\n",
        "print(\"CNN Model training complete.\")\n",
        "\n",
        "# Make predictions\n",
        "predictions_cnn = model_cnn.predict(X_test_cnn)\n",
        "\n",
        "# Evaluate the model\n",
        "loss_cnn = model_cnn.evaluate(X_test_cnn, y_test_cnn, verbose=0)\n",
        "print(f'Test Loss (MSE): {loss_cnn}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q4Z27H5aaQr-",
        "outputId": "a0cd5212-a199-4bd3-a426-8f8940b66e4a"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CNN Model training complete.\n",
            "\u001b[1m31/31\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step\n",
            "Test Loss (MSE): 1.754393997543957e-05\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_cnn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HfxipBI0b_Rv",
        "outputId": "98a3355c-86ce-46c0-ee2b-024ad45ae861"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[0.20330484],\n",
              "        [0.16898255],\n",
              "        [0.72897246],\n",
              "        ...,\n",
              "        [0.66790065],\n",
              "        [0.70407589],\n",
              "        [0.00167076]],\n",
              "\n",
              "       [[0.19721536],\n",
              "        [0.15817442],\n",
              "        [0.62362193],\n",
              "        ...,\n",
              "        [0.51904775],\n",
              "        [0.56111363],\n",
              "        [0.00162045]],\n",
              "\n",
              "       [[0.19267985],\n",
              "        [0.16656513],\n",
              "        [0.64188034],\n",
              "        ...,\n",
              "        [0.54082422],\n",
              "        [0.58246737],\n",
              "        [0.00162513]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[0.99487025],\n",
              "        [0.9134738 ],\n",
              "        [0.14549955],\n",
              "        ...,\n",
              "        [0.55337514],\n",
              "        [0.59470457],\n",
              "        [0.78570544]],\n",
              "\n",
              "       [[0.99455984],\n",
              "        [0.91276804],\n",
              "        [0.11777581],\n",
              "        ...,\n",
              "        [0.53259941],\n",
              "        [0.57442044],\n",
              "        [0.78403144]],\n",
              "\n",
              "       [[0.99536997],\n",
              "        [0.91447025],\n",
              "        [0.15292187],\n",
              "        ...,\n",
              "        [0.69207004],\n",
              "        [0.72664671],\n",
              "        [0.82424574]]])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Perfomance Statistics Indicators"
      ],
      "metadata": {
        "id": "tqDJqqHzbib5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perfomance Statistics Indicators\n",
        "from sklearn.metrics import r2_score, mean_absolute_error, mean_absolute_percentage_error\n",
        "\n",
        "# Calculate R2 score\n",
        "r2 = r2_score(y_test_cnn, predictions_cnn)\n",
        "print(f'R2 Score: {r2}')\n",
        "\n",
        "# Calculate Mean Absolute Error (MAE)\n",
        "mae = mean_absolute_error(y_test_cnn, predictions_cnn)\n",
        "print(f'Mean Absolute Error (MAE): {mae}')\n",
        "\n",
        "# Calculate Mean Absolute Percentage Error (MAPE)\n",
        "# Avoid division by zero for MAPE\n",
        "mape = mean_absolute_percentage_error(y_test_cnn, predictions_cnn)\n",
        "print(f'Mean Absolute Percentage Error (MAPE): {mape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MoIRzsXybW25",
        "outputId": "a6fb0895-efe4-41d1-c1c7-d8f97fcde820"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R2 Score: 0.9997561002247819\n",
            "Mean Absolute Error (MAE): 0.0033091587197743213\n",
            "Mean Absolute Percentage Error (MAPE): 0.1908804018549231\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: i want to run a cnn regression with depended variable the normalized apple close price and as features - independed variable all the trend technical indicators from  trend_indicators_normalized df\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Dense\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Ensure the data is aligned\n",
        "# Check if indices are the same\n",
        "if not trend_indicators_normalized.index.equals(aapl_close_normalized.index):\n",
        "  print(\"Warning: Indices of features and target do not match. Re-indexing.\")\n",
        "  # Reindex aapl_close_normalized to match trend_indicators_normalized\n",
        "  aapl_close_normalized = aapl_close_normalized.reindex(trend_indicators_normalized.index)\n",
        "\n",
        "# Drop rows with NaN values that might have been introduced after reindexing or initial calculations\n",
        "combined_df = pd.concat([trend_indicators_normalized, aapl_close_normalized], axis=1).dropna()\n",
        "X = combined_df[trend_indicators_normalized.columns].values\n",
        "y = combined_df['Close'].values\n",
        "\n",
        "# Reshape features for CNN (samples, timesteps, features)\n",
        "# For a 1D CNN, timesteps can be 1 if each data point is treated independently.\n",
        "# If you want to consider sequences of data, you would need to structure your data differently.\n",
        "# For simplicity, we'll treat each row as a single timestep for now.\n",
        "X = X.reshape(X.shape[0], X.shape[1], 1) # Reshape to (samples, features, 1)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the CNN model\n",
        "model = Sequential([\n",
        "    Conv1D(filters=32, kernel_size=3, activation='relu', input_shape=(X_train.shape[1], 1)),\n",
        "    MaxPooling1D(pool_size=2),\n",
        "    Conv1D(filters=64, kernel_size=3, activation='relu'),\n",
        "    MaxPooling1D(pool_size=2),\n",
        "    Flatten(),\n",
        "    Dense(50, activation='relu'),\n",
        "    Dense(1) # Output layer for regression\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2)\n",
        "\n",
        "# Evaluate the model\n",
        "loss = model.evaluate(X_test, y_test, verbose=0)\n",
        "print(f'Test Loss (MSE): {loss}')\n",
        "\n",
        "# Make predictions\n",
        "predictions = model.predict(X_test)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "id": "0chJAPw7Bv5-",
        "outputId": "9068555b-3cef-4eb2-eecc-c83fa3a6ddfa"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mget_attr\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1585\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mc_api_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m:\u001b[0m   \u001b[0;31m# pytype: disable=wrong-arg-count\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1586\u001b[0;31m         \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_OperationGetAttrValueProto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1587\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Operation 'sequential_2_1/dense_4_1/BiasAdd/ReadVariableOp/resource' has no attr named '_class'.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-314240455.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;31m# Evaluate the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    115\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 117\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    118\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[1;32m    375\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterator\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mepoch_iterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m                     \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mfunction\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0miterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDistributedIterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m             ):\n\u001b[0;32m--> 220\u001b[0;31m                 \u001b[0mopt_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmulti_step_on_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mopt_outputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    694\u001b[0m     )\n\u001b[1;32m    695\u001b[0m     \u001b[0;31m# Force the definition of the function for these arguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 696\u001b[0;31m     self._concrete_variable_creation_fn = tracing_compilation.trace_function(\n\u001b[0m\u001b[1;32m    697\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mtrace_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    176\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m     concrete_function = _maybe_define_function(\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracing_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m           \u001b[0mtarget_func_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlookup_func_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m         concrete_function = _create_concrete_function(\n\u001b[0m\u001b[1;32m    284\u001b[0m             \u001b[0mtarget_func_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlookup_func_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracing_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36m_create_concrete_function\u001b[0;34m(function_type, type_context, func_graph, tracing_options)\u001b[0m\n\u001b[1;32m    308\u001b[0m       \u001b[0mattributes_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLE_ACD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m   )\n\u001b[0;32m--> 310\u001b[0;31m   traced_func_graph = func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m    311\u001b[0m       \u001b[0mtracing_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m       \u001b[0mtracing_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders)\u001b[0m\n\u001b[1;32m   1058\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1060\u001b[0;31m     \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1061\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m     \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/autograph_util.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;34m\"\"\"Calls a converted version of original_func.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m       return api.converted_call(\n\u001b[0m\u001b[1;32m     42\u001b[0m           \u001b[0moriginal_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    337\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mis_autograph_artifact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Permanently allowed: %s: AutoGraph artifact'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m   \u001b[0;31m# If this is a partial, unwrap it and redo all the checks.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mControlStatusCtx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mmulti_step_on_iterator\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msteps_per_execution\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m                 return tf.experimental.Optional.from_value(\n\u001b[0;32m--> 133\u001b[0;31m                     \u001b[0mone_step_on_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_next\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m                 )\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    831\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    832\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 833\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    834\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    835\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0;31m# This is the first call of __call__, so we have to initialize.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m       \u001b[0minitializers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    891\u001b[0m       \u001b[0;31m# At this point we know that the initialization is complete (or less\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, args, kwds, add_initializers_to)\u001b[0m\n\u001b[1;32m    694\u001b[0m     )\n\u001b[1;32m    695\u001b[0m     \u001b[0;31m# Force the definition of the function for these arguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 696\u001b[0;31m     self._concrete_variable_creation_fn = tracing_compilation.trace_function(\n\u001b[0m\u001b[1;32m    697\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    698\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36mtrace_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    176\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m     concrete_function = _maybe_define_function(\n\u001b[0m\u001b[1;32m    179\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracing_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    281\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    282\u001b[0m           \u001b[0mtarget_func_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlookup_func_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 283\u001b[0;31m         concrete_function = _create_concrete_function(\n\u001b[0m\u001b[1;32m    284\u001b[0m             \u001b[0mtarget_func_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlookup_func_context\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtracing_options\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py\u001b[0m in \u001b[0;36m_create_concrete_function\u001b[0;34m(function_type, type_context, func_graph, tracing_options)\u001b[0m\n\u001b[1;32m    308\u001b[0m       \u001b[0mattributes_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLE_ACD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m   )\n\u001b[0;32m--> 310\u001b[0;31m   traced_func_graph = func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m    311\u001b[0m       \u001b[0mtracing_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m       \u001b[0mtracing_options\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, create_placeholders)\u001b[0m\n\u001b[1;32m   1058\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1060\u001b[0;31m     \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1061\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1062\u001b[0m     \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    597\u001b[0m         \u001b[0;31m# the function a weak reference to itself to avoid a reference cycle.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    598\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcompile_with_xla\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 599\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    600\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/autograph_util.py\u001b[0m in \u001b[0;36mautograph_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0;34m\"\"\"Calls a converted version of original_func.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m       return api.converted_call(\n\u001b[0m\u001b[1;32m     42\u001b[0m           \u001b[0moriginal_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m           \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mconverted_call\u001b[0;34m(f, args, kwargs, caller_fn_scope, options)\u001b[0m\n\u001b[1;32m    337\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mis_autograph_artifact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Permanently allowed: %s: AutoGraph artifact'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_call_unconverted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m   \u001b[0;31m# If this is a partial, unwrap it and redo all the checks.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36m_call_unconverted\u001b[0;34m(f, args, kwargs, options, update_cache)\u001b[0m\n\u001b[1;32m    457\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    458\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 459\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    460\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mControlStatusCtx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mone_step_on_data\u001b[0;34m(data)\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mone_step_on_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0;34m\"\"\"Runs a single training step on a batch of data.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdistribute_strategy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m             outputs = reduce_per_replica(\n\u001b[1;32m    116\u001b[0m                 \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   1671\u001b[0m       fn = autograph.tf_convert(\n\u001b[1;32m   1672\u001b[0m           fn, autograph_ctx.control_status_ctx(), convert_by_default=False)\n\u001b[0;32m-> 1673\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extended\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1675\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mcall_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   3261\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3262\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3263\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3265\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36m_call_for_each_replica\u001b[0;34m(self, fn, args, kwargs)\u001b[0m\n\u001b[1;32m   4059\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_for_each_replica\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4060\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mReplicaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplica_id_in_sync_group\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4061\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4062\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4063\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_reduce_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestinations\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/autograph/impl/api.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    642\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mControlStatusCtx\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstatus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mag_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDISABLED\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 643\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    644\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    645\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mismethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/trainer.py\u001b[0m in \u001b[0;36mtrain_step\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0;31m# Update weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgradients\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"The model does not have any trainable weights.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/optimizers/base_optimizer.py\u001b[0m in \u001b[0;36mapply_gradients\u001b[0;34m(self, grads_and_vars)\u001b[0m\n\u001b[1;32m    461\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_gradients\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    462\u001b[0m         \u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable_variables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 463\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    464\u001b[0m         \u001b[0;31m# Return iterations for compat with tf.keras.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    465\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/optimizers/base_optimizer.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, grads, trainable_variables)\u001b[0m\n\u001b[1;32m    500\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaller\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    503\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_variables_are_known\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainable_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/optimizers/adam.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, var_list)\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 93\u001b[0;31m         self._momentums, self._velocities = self.add_optimizer_variables(\n\u001b[0m\u001b[1;32m     94\u001b[0m             \u001b[0mvar_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"momentum\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"velocity\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     95\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/optimizers/base_optimizer.py\u001b[0m in \u001b[0;36madd_optimizer_variables\u001b[0;34m(self, trainable_variables, name, initializer)\u001b[0m\n\u001b[1;32m    388\u001b[0m                 ):\n\u001b[1;32m    389\u001b[0m                     optimizer_variables[i].append(\n\u001b[0;32m--> 390\u001b[0;31m                         self.add_variable_from_reference(\n\u001b[0m\u001b[1;32m    391\u001b[0m                             \u001b[0mvariable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m                             \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvar_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/optimizer.py\u001b[0m in \u001b[0;36madd_variable_from_reference\u001b[0;34m(self, reference_variable, name, initializer)\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0mcolocate_var\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         ):\n\u001b[0;32m---> 35\u001b[0;31m             return super().add_variable_from_reference(\n\u001b[0m\u001b[1;32m     36\u001b[0m                 \u001b[0mreference_variable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/optimizers/base_optimizer.py\u001b[0m in \u001b[0;36madd_variable_from_reference\u001b[0;34m(self, reference_variable, name, initializer)\u001b[0m\n\u001b[1;32m    318\u001b[0m                 \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m             )\n\u001b[0;32m--> 320\u001b[0;31m         return self.add_variable(\n\u001b[0m\u001b[1;32m    321\u001b[0m             \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreference_variable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m             \u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/optimizers/base_optimizer.py\u001b[0m in \u001b[0;36madd_variable\u001b[0;34m(self, shape, initializer, dtype, aggregation, layout, name)\u001b[0m\n\u001b[1;32m    272\u001b[0m         \u001b[0minitializer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minitializers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaller\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 274\u001b[0;31m             variable = backend.Variable(\n\u001b[0m\u001b[1;32m    275\u001b[0m                 \u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m                 \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/common/variables.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    204\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize_with_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minitializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/core.py\u001b[0m in \u001b[0;36m_initialize_with_initializer\u001b[0;34m(self, initializer)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_initialize_with_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitializer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minitializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_deferred_initialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/keras/src/backend/tensorflow/core.py\u001b[0m in \u001b[0;36m_initialize\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m             self._value = tf.Variable(\n\u001b[0m\u001b[1;32m     43\u001b[0m                 \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m                 \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    196\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"_variable_call\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_call\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 198\u001b[0;31m       \u001b[0mvariable_call\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mvariable_call\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvariable_call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m_variable_call\u001b[0;34m(cls, initial_value, trainable, validate_shape, caching_device, name, variable_def, dtype, import_scope, constraint, synchronization, aggregation, shape, experimental_enable_variable_lifting, **kwargs)\u001b[0m\n\u001b[1;32m   1228\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0maggregation\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1229\u001b[0m       \u001b[0maggregation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariableAggregation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNONE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1230\u001b[0;31m     return previous_getter(\n\u001b[0m\u001b[1;32m   1231\u001b[0m         \u001b[0minitial_value\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_value\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1232\u001b[0m         \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36mgetter\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mgetter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcaptured_getter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcaptured_previous\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mgetter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mcreator\u001b[0;34m(next_creator, **kwargs)\u001b[0m\n\u001b[1;32m   3974\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_creator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3975\u001b[0m       \u001b[0m_require_strategy_scope_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3976\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mnext_creator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3977\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3978\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_var_creator_scope\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvariable_scope\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcreator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36mgetter\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mgetter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcaptured_getter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcaptured_previous\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mgetter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/distribute/distribute_lib.py\u001b[0m in \u001b[0;36mcreator\u001b[0;34m(next_creator, **kwargs)\u001b[0m\n\u001b[1;32m   3974\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcreator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_creator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3975\u001b[0m       \u001b[0m_require_strategy_scope_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstrategy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3976\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mnext_creator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3977\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3978\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_var_creator_scope\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvariable_scope\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable_creator_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcreator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36mgetter\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mgetter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mcaptured_getter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcaptured_previous\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mgetter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36mvariable_capturing_scope\u001b[0;34m(next_creator, **kwds)\u001b[0m\n\u001b[1;32m    682\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0menable_variable_lifting\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    683\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnext_creator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 684\u001b[0;31m       v = UnliftedInitializerVariable(\n\u001b[0m\u001b[1;32m    685\u001b[0m           \u001b[0madd_initializers_to\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0madd_initializers_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    686\u001b[0m       )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/ops/variables.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mvariable_call\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mvariable_call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVariableMetaclass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, initial_value, trainable, caching_device, name, dtype, constraint, add_initializers_to, synchronization, aggregation, shape, **unused_kwargs)\u001b[0m\n\u001b[1;32m    385\u001b[0m         \u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m         cond.cond(\n\u001b[0;32m--> 387\u001b[0;31m             \u001b[0mresource_variable_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvar_is_initialized_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    388\u001b[0m             not_assign_fn, assign_fn)\n\u001b[1;32m    389\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/ops/gen_resource_variable_ops.py\u001b[0m in \u001b[0;36mvar_is_initialized_op\u001b[0;34m(resource, name)\u001b[0m\n\u001b[1;32m   1379\u001b[0m       \u001b[0;32mpass\u001b[0m  \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1380\u001b[0m   \u001b[0;31m# Add nodes to the TensorFlow graph.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1381\u001b[0;31m   _, _, _op, _outputs = _op_def_library._apply_op_helper(\n\u001b[0m\u001b[1;32m   1382\u001b[0m         \"VarIsInitializedOp\", resource=resource, name=name)\n\u001b[1;32m   1383\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    794\u001b[0m       \u001b[0;31m# Add Op to graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    795\u001b[0m       \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 796\u001b[0;31m       op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n\u001b[0m\u001b[1;32m    797\u001b[0m                                  \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    798\u001b[0m                                  attrs=attr_protos, op_def=op_def)\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m    612\u001b[0m       \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    613\u001b[0m       \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 614\u001b[0;31m     return super()._create_op_internal(  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m    615\u001b[0m         \u001b[0mop_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    616\u001b[0m         compute_device)\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m   2713\u001b[0m           \u001b[0mop_def\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mop_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m       )\n\u001b[0;32m-> 2715\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_op_helper\u001b[0;34m(self, op, compute_device)\u001b[0m\n\u001b[1;32m   2804\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mcolocation_op\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_colocation_stack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpeek_objs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2805\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2806\u001b[0;31m           \u001b[0mall_colocation_groups\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolocation_op\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolocation_groups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2807\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2808\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mcolocation_groups\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1276\u001b[0m     \u001b[0mdefault_colocation_group\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loc:@%s\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1277\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1278\u001b[0;31m       \u001b[0mclass_attr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_attr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"_class\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1279\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1280\u001b[0m       \u001b[0;31m# This op has no explicit colocation group, so it is itself its\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36mget_attr\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1583\u001b[0m     \u001b[0mfields\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"i\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"f\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"type\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"shape\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"tensor\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"func\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1584\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1585\u001b[0;31m       \u001b[0;32mwith\u001b[0m \u001b[0mc_api_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtf_buffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m:\u001b[0m   \u001b[0;31m# pytype: disable=wrong-arg-count\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1586\u001b[0m         \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_OperationGetAttrValueProto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_c_op\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1587\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.11/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, typ, value, traceback)\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"generator didn't yield\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtyp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtyp\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### compare predictions to y_test"
      ],
      "metadata": {
        "id": "htuB9xyMJ92R"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# compare predictions to y_test\n",
        "print(predictions[:10])\n",
        "print(y_test[:10])"
      ],
      "metadata": {
        "id": "AlfQoF8ZClfN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Perfomance Statistics Indicators"
      ],
      "metadata": {
        "id": "JAdjil0vKAem"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perfomance Statistics Indicators\n",
        "from sklearn.metrics import r2_score, mean_absolute_error, mean_absolute_percentage_error\n",
        "\n",
        "# Calculate R2 score\n",
        "r2 = r2_score(y_test, predictions)\n",
        "print(f'R2 Score: {r2}')\n",
        "\n",
        "# Calculate Mean Absolute Error (MAE)\n",
        "mae = mean_absolute_error(y_test, predictions)\n",
        "print(f'Mean Absolute Error (MAE): {mae}')\n",
        "\n",
        "# Calculate Mean Absolute Percentage Error (MAPE)\n",
        "# Avoid division by zero for MAPE\n",
        "mape = mean_absolute_percentage_error(y_test, predictions)\n",
        "print(f'Mean Absolute Percentage Error (MAPE): {mape}')"
      ],
      "metadata": {
        "id": "p7LledXhCqil"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Price Predictions after unnormalize the price"
      ],
      "metadata": {
        "id": "DHqyhPr-KEhU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: give a price prediction after unnormalize the price\n",
        "\n",
        "# To unnormalize the price predictions, we need to use the scaler that was fitted on the original 'Close' prices.\n",
        "# The scaler used for normalizing the 'Close' price was `scaler` applied to `aapl_data[['Close']]`.\n",
        "# We need to create a new scaler instance or refit the existing one *only* on the original 'Close' prices\n",
        "# if the original `scaler` was modified later. However, looking at the code, the original `scaler`\n",
        "# was fitted on `trend_indicators` and then on `aapl_data[['Close']]`. The fitting on `aapl_data[['Close']]`\n",
        "# is the one we need for inverse transformation.\n",
        "\n",
        "# Create a new scaler and fit it only on the original 'Close' data\n",
        "price_scaler = MinMaxScaler()\n",
        "price_scaler.fit(aapl_data[['Close']].dropna()) # Use original close data and handle potential NaNs\n",
        "\n",
        "# Inverse transform the normalized predictions\n",
        "unnormalized_predictions = price_scaler.inverse_transform(predictions)\n",
        "\n",
        "# Inverse transform the normalized test labels for comparison\n",
        "unnormalized_y_test = price_scaler.inverse_transform(y_test.reshape(-1, 1))\n",
        "\n",
        "print(\"Unnormalized Predictions:\")\n",
        "print(unnormalized_predictions[:10])\n",
        "\n",
        "print(\"\\nOriginal Test Prices:\")\n",
        "print(unnormalized_y_test[:10])"
      ],
      "metadata": {
        "id": "csrUN6KkEujy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Statisticall signicance and  prediction  validation"
      ],
      "metadata": {
        "id": "mwbHwYQzKRHM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# these results are statistically signicant and the prediction are valid?\n",
        "\n",
        "''' This script implements a common approach to using technical indicators and a simple CNN for predicting stock prices (specifically, the next closing price based on the current technical indicators). Let's break down the results and discuss their statistical significance and the validity of the predictions.\n",
        "\n",
        "**Understanding the Code and Results:**\n",
        "\n",
        "1.  **Data Acquisition and Feature Engineering:**\n",
        "    *   It downloads historical AAPL data.\n",
        "    *   It calculates a comprehensive set of technical indicators using the `ta` library.\n",
        "    *   It then specifically selects only the 'trend' indicators as features (X). This is a deliberate choice, potentially based on an assumption about the relevance of trend indicators.\n",
        "    *   Both the features (trend indicators) and the target ('Close' price) are normalized using `MinMaxScaler`. This is important for neural networks.\n",
        "\n",
        "2.  **Data Preparation for CNN:**\n",
        "    *   The data is combined and rows with `NaN` values are dropped. This is crucial as many technical indicators will have `NaN` values at the beginning of the time series due to the lookback periods required for their calculation.\n",
        "    *   The features `X` are reshaped for the 1D CNN. The current reshaping `(samples, features, 1)` treats each point in time independently, where the 'features' dimension represents the different technical indicators at that specific point. If you wanted to consider sequences of data over time (e.g., using the last `n` days of indicators to predict the next day's price), you would need a different data preparation strategy (e.g., using sliding windows).\n",
        "\n",
        "3.  **Model Definition and Training:**\n",
        "    *   A simple Sequential CNN model is defined with two 1D convolutional layers, pooling layers, a flatten layer, and dense layers. The output layer has a single neuron for regression.\n",
        "    *   The model is compiled with the 'adam' optimizer and 'mse' (Mean Squared Error) as the loss function, which are standard choices for regression.\n",
        "    *   The model is trained for 50 epochs.\n",
        "\n",
        "4.  **Evaluation Metrics:**\n",
        "    *   **Test Loss (MSE):** This is the mean squared difference between the actual and predicted normalized closing prices on the test set. A lower MSE indicates better performance in terms of minimizing the squared errors.\n",
        "    *   **R2 Score:** This represents the proportion of the variance in the dependent variable (closing price) that is predictable from the independent variables (trend indicators). An R2 score close to 1 indicates that the model explains a large portion of the variance. An R2 score close to 0 suggests the model doesn't explain the variance well. A negative R2 score means the model performs worse than simply predicting the mean of the target variable.\n",
        "    *   **Mean Absolute Error (MAE):** This is the average absolute difference between the actual and predicted normalized closing prices. It gives a more intuitive sense of the average error size than MSE.\n",
        "    *   **Mean Absolute Percentage Error (MAPE):** This measures the average percentage difference between the actual and predicted values. It's useful for understanding the relative error size. However, it can be unstable or infinite if the actual values are zero or close to zero.\n",
        "\n",
        "**Analyzing the Statistical Significance and Prediction Validity:**\n",
        "\n",
        "Whether the results are \"statistically significant\" and the predictions are \"valid\" depends heavily on several factors beyond just the metric values:\n",
        "\n",
        "**Factors Influencing Statistical Significance and Validity:**\n",
        "\n",
        "1.  **Data Size and Timeframe:** One year of data is relatively short for stock price prediction, especially if you're relying on historical patterns. Market dynamics can change significantly.\n",
        "2.  **Feature Selection:** You've specifically chosen only 'trend' indicators. Are these the most relevant features for predicting AAPL's price? Have you considered other categories like momentum, volatility, or volume indicators? The performance might improve or worsen with a different set of features.\n",
        "3.  **Model Complexity and Architecture:** The CNN architecture is relatively simple. For time series data like stock prices, more sophisticated architectures like LSTMs or GRUs are often considered, which are specifically designed to handle sequential data and capture temporal dependencies. While the reshaping used treats each time step independently, this might not be the optimal approach for stock prediction.\n",
        "4.  **Hyperparameter Tuning:** The number of filters, kernel sizes, pool sizes, number of layers, epochs, and batch size are hyperparameters that were chosen likely without extensive tuning. Optimizing these could significantly impact the model's performance.\n",
        "5.  **Overfitting:** With only 50 epochs and a relatively simple dataset (compared to the complexity of stock markets), overfitting is a potential risk. The model might be learning the training data too well, including noise, and thus performing poorly on unseen test data. The `validation_split` during training helps monitor this, but it's not a guarantee.\n",
        "6.  **Market Efficiency and Predictability:** Stock markets are notoriously difficult to predict due to their efficiency (prices reflect available information quickly) and the influence of many external factors not captured in the technical indicators (news, economic events, investor sentiment, etc.). Relying solely on technical indicators for precise price prediction is highly challenging.\n",
        "7.  **Evaluation on Unseen Data (Beyond the Test Set):** The test set provides an estimate of performance on unseen data *from the same period as the training data*. True validation of a stock prediction model requires testing its performance on future data that was not available during training or testing. This is called \"out-of-sample\" or \"forward\" testing.\n",
        "8.  **Assumptions of the Model:** The model assumes that historical relationships between technical indicators and price movements will continue into the future. This is a strong assumption in dynamic markets.\n",
        "9.  **Statistical Significance of Evaluation Metrics:** While you have metrics, formal statistical tests to determine if the model's performance is significantly better than a baseline (like predicting the mean or the previous day's price) would be needed for a rigorous claim of statistical significance. For example, you could compare the model's error distribution to the error distribution of a simple baseline model.\n",
        "10. **Business Context and Thresholds:** What constitutes \"valid\" predictions depends on the intended use case. For high-frequency trading, small errors might be acceptable if the volume is high. For long-term investment, larger errors might be tolerated.\n",
        "\n",
        "**Interpreting the Metric Values:**\n",
        "\n",
        "*   **Test Loss (MSE):** A small MSE on normalized data is good, but without context of the scale of the normalized target variable, it's hard to judge its absolute magnitude.\n",
        "*   **R2 Score:** The R2 score is a key indicator of how much variance your features explain. A low R2 score (especially close to 0 or negative) would strongly suggest that the model is not capturing the underlying patterns well and the predictions are not valid. A high R2 score is more promising but doesn't guarantee profitability or robustness.\n",
        "*   **MAE and MAPE:** These give a sense of the average error in absolute and percentage terms. They are often easier to interpret than MSE.\n",
        "\n",
        "**Conclusion:**\n",
        "\n",
        "Based *solely* on the provided code and the calculated evaluation metrics, you can say:\n",
        "\n",
        "*   You have trained a CNN model using trend technical indicators to predict the normalized closing price of AAPL.\n",
        "*   The calculated metrics (MSE, R2, MAE, MAPE) provide a quantitative assessment of the model's performance on the held-out test set *within the single year of data*.\n",
        "\n",
        "**However, you absolutely cannot definitively say that the results are statistically significant or that the predictions are valid for future performance without:**\n",
        "\n",
        "1.  **More rigorous statistical testing** comparing your model to a baseline.\n",
        "2.  **Extensive backtesting or forward testing** on completely unseen future data.\n",
        "3.  **Consideration of other features, model architectures, and hyperparameter tuning.**\n",
        "4.  **Understanding the limitations of using only technical indicators** in a complex, efficient market.\n",
        "5.  **A clear definition of what constitutes \"valid\" predictions** in your specific context.\n",
        "\n",
        "**In summary, the code provides a starting point and performance metrics on a limited dataset. While the metrics give you a sense of how well the model fits the test data, claiming statistical significance or prediction validity requires significantly more analysis, validation, and consideration of the inherent difficulties in stock market prediction.** '''"
      ],
      "metadata": {
        "id": "wFvVgtoeDLlm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Build and train lstm model**\n"
      ],
      "metadata": {
        "id": "3EE8nNCcK0CH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Import Libraries and select the features"
      ],
      "metadata": {
        "id": "5IPYpnfNK8uE"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fn0VY1Th42aD"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Select only the trend indicators again\n",
        "trend_indicators = aapl_data[['trend_macd', 'trend_macd_signal', 'trend_macd_diff', 'trend_sma_fast', 'trend_sma_slow', 'trend_ema_fast', 'trend_ema_slow', 'trend_adx', 'trend_adx_pos', 'trend_adx_neg', 'trend_vortex_ind_pos', 'trend_vortex_ind_neg', 'trend_vortex_ind_diff', 'trend_trix', 'trend_mass_index', 'trend_dpo', 'trend_kst', 'trend_kst_sig', 'trend_ichimoku_conv', 'trend_ichimoku_base', 'trend_ichimoku_a', 'trend_ichimoku_b', 'trend_cci', 'trend_aroon_up', 'trend_aroon_down', 'trend_aroon_ind']]\n",
        "\n",
        "\n",
        "def create_sequences(data, feature_cols, target_col, lookback_window):\n",
        "  \"\"\"\n",
        "  Creates sequences of technical indicators and corresponding target variables for LSTM.\n",
        "\n",
        "  Args:\n",
        "    data: pandas DataFrame containing the data.\n",
        "    feature_cols: List of column names for the features (technical indicators).\n",
        "    target_col: Name of the target column ('price_trend').\n",
        "    lookback_window: The number of previous time steps to include in each sequence.\n",
        "\n",
        "  Returns:\n",
        "    A tuple containing two NumPy arrays:\n",
        "      - X: NumPy array of sequences (samples, lookback_window, features).\n",
        "      - y: NumPy array of target variables (samples,).\n",
        "  \"\"\"\n",
        "  X, y = [], []\n",
        "  for i in range(lookback_window, len(data)):\n",
        "    X.append(data[feature_cols].iloc[i-lookback_window:i].values)\n",
        "    y.append(data[target_col].iloc[i])\n",
        "  return np.array(X), np.array(y)\n",
        "\n",
        "# Define the lookback window size\n",
        "lookback_window_size = 20\n",
        "\n",
        "# Create sequences for LSTM\n",
        "X_lstm, y_lstm = create_sequences(aapl_data, trend_indicators.columns.tolist(), 'price_trend', lookback_window_size)\n",
        "\n",
        "print(\"Shape of X_lstm:\", X_lstm.shape)\n",
        "print(\"Shape of y_lstm:\", y_lstm.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7815c3a6"
      },
      "source": [
        "## Split data\n",
        "\n",
        "### Subtask:\n",
        "Split the sequential data into training and testing sets. It's important to split the data chronologically to simulate a real-world scenario for out-of-sample testing.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6add8a65"
      },
      "source": [
        "**Reasoning**:\n",
        "Split the sequential data chronologically into training and testing sets and print their shapes.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7aa27165"
      },
      "source": [
        "# Determine the size of the training set (e.g., 80%)\n",
        "train_size = int(len(X_lstm) * 0.8)\n",
        "\n",
        "# Calculate the index to split the data\n",
        "split_index = train_size\n",
        "\n",
        "# Split the data into training and testing sets chronologically\n",
        "X_train_lstm, X_test_lstm = X_lstm[:split_index], X_lstm[split_index:]\n",
        "y_train_lstm, y_test_lstm = y_lstm[:split_index], y_lstm[split_index:]\n",
        "\n",
        "# Print the shapes of the training and testing sets\n",
        "print(\"Shape of X_train_lstm:\", X_train_lstm.shape)\n",
        "print(\"Shape of X_test_lstm:\", X_test_lstm.shape)\n",
        "print(\"Shape of y_train_lstm:\", y_train_lstm.shape)\n",
        "print(\"Shape of y_test_lstm:\", y_test_lstm.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9fd8994a"
      },
      "source": [
        "## Build and train lstm model\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "### Subtask:\n",
        "Define and train an LSTM classification model using the prepared training data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6330412d"
      },
      "source": [
        "**Reasoning**:\n",
        "Import the necessary Keras layers and define the LSTM classification model architecture.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "205b16aa"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "\n",
        "# Define the LSTM model\n",
        "model = Sequential([\n",
        "    LSTM(units=100, return_sequences=False, input_shape=(X_train_lstm.shape[1], X_train_lstm.shape[2])),\n",
        "    Dropout(0.3),\n",
        "    Dense(50, activation='relu'),\n",
        "    Dense(1, activation='sigmoid') # Output layer for binary classification\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Print the model summary\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7fc016a9"
      },
      "source": [
        "**Reasoning**:\n",
        "Train the defined LSTM model using the prepared training data and validation split.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "As3bLJtf5BMY"
      },
      "source": [
        "# Train the model\n",
        "history = model.fit(X_train_lstm, y_train_lstm, epochs=50, batch_size=32, validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76a42dff"
      },
      "source": [
        "**Reasoning**:\n",
        "The error indicates an invalid dtype ('str128') in the input data for the model. This is likely because the 'price_trend' target variable, which contains string values ('up' or 'down'), has not been properly encoded into numerical format for the classification model. The target variable needs to be converted to a binary representation (e.g., 0 and 1).\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FjWsLhMP5DAt"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Initialize the LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Encode the string labels in y_train_lstm and y_test_lstm\n",
        "y_train_lstm_encoded = label_encoder.fit_transform(y_train_lstm)\n",
        "y_test_lstm_encoded = label_encoder.transform(y_test_lstm)\n",
        "\n",
        "# Train the model with the encoded target variable\n",
        "history = model.fit(X_train_lstm, y_train_lstm_encoded, epochs=50, batch_size=32, validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8b7bc53a"
      },
      "source": [
        "## Prediction\n",
        "Predict the 'Close' price of a stock using all available technical indicators from the `ta` library as features. Train a regression model on in-sample data and evaluate its performance on both in-sample and out-of-sample data, reporting relevant regression metrics."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "250dbdf0"
      },
      "source": [
        "## Prepare data for the regression\n",
        "\n",
        "### Subtask:\n",
        "Select all technical indicators as features (X) and the normalized 'Close' price as the target variable (y). Handle any missing values.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbc3c7d1"
      },
      "source": [
        "**Reasoning**:\n",
        "Select technical indicator columns, the 'Close' price, handle missing values, and normalize both features and target.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3294e96c"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "# Identify technical indicator columns\n",
        "original_cols = ['Open', 'High', 'Low', 'Close', 'Volume', 'Dividends', 'Stock Splits']\n",
        "technical_indicator_cols = [col for col in aapl_data.columns if col not in original_cols]\n",
        "\n",
        "# Create feature DataFrame (X) and target Series (y)\n",
        "X = aapl_data[technical_indicator_cols].copy()\n",
        "y = aapl_data['Close'].copy()\n",
        "\n",
        "# Combine X and y to drop rows with NaN values simultaneously\n",
        "combined_df = pd.concat([X, y], axis=1).dropna()\n",
        "\n",
        "# Separate the combined DataFrame back into X and y\n",
        "X_cleaned = combined_df[technical_indicator_cols]\n",
        "y_cleaned = combined_df['Close']\n",
        "\n",
        "# Initialize the MinMaxScaler\n",
        "scaler_X = MinMaxScaler()\n",
        "scaler_y = MinMaxScaler()\n",
        "\n",
        "# Normalize the features (X) and target (y)\n",
        "X_scaled = scaler_X.fit_transform(X_cleaned)\n",
        "y_scaled = scaler_y.fit_transform(y_cleaned.values.reshape(-1, 1))\n",
        "\n",
        "# Print the shapes of the resulting scaled data\n",
        "print(\"Shape of X_scaled:\", X_scaled.shape)\n",
        "print(\"Shape of y_scaled:\", y_scaled.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fa9027a6"
      },
      "source": [
        "**Reasoning**:\n",
        "The error \"Found array with 0 sample(s)\" indicates that after dropping rows with NaN values, the resulting `X_cleaned` DataFrame is empty. This suggests that all rows in the `combined_df` (which is a concatenation of `X` and `y`) contained at least one NaN value in the technical indicator columns. I need to inspect the `combined_df` and `X_cleaned` after the `dropna()` step to confirm this and potentially handle the missing values in a different way if necessary, or at least understand why all rows are being dropped.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjIq_veoD41n"
      },
      "source": [
        "# Inspect the combined_df after dropping NaNs\n",
        "print(\"Shape of combined_df after dropping NaNs:\", combined_df.shape)\n",
        "print(\"First few rows of combined_df after dropping NaNs:\")\n",
        "display(combined_df.head())\n",
        "\n",
        "# Inspect the X_cleaned DataFrame\n",
        "print(\"\\nShape of X_cleaned:\", X_cleaned.shape)\n",
        "print(\"First few rows of X_cleaned:\")\n",
        "display(X_cleaned.head())\n",
        "\n",
        "# Check if X_cleaned is empty\n",
        "if X_cleaned.empty:\n",
        "    print(\"\\nX_cleaned is empty after dropping NaNs. All rows contained missing values in the technical indicators.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8e36f6ee"
      },
      "source": [
        "**Reasoning**:\n",
        "Since dropping all rows with NaNs resulted in an empty DataFrame, I need to handle the missing values differently. A common approach for time series data with NaNs at the beginning (due to lookback periods for indicator calculations) is to fill them. I will fill the NaNs using a forward fill method, which carries the last valid observation forward. After filling, I will proceed with normalization.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e77f3d9e"
      },
      "source": [
        "# Fill NaN values using forward fill\n",
        "X.fillna(method='ffill', inplace=True)\n",
        "y.fillna(method='ffill', inplace=True)\n",
        "\n",
        "# Now, drop any remaining NaNs that couldn't be forward-filled (e.g., NaNs at the very beginning)\n",
        "combined_df = pd.concat([X, y], axis=1).dropna()\n",
        "\n",
        "# Separate the combined DataFrame back into X and y\n",
        "X_cleaned = combined_df[technical_indicator_cols]\n",
        "y_cleaned = combined_df['Close']\n",
        "\n",
        "# Initialize the MinMaxScaler\n",
        "scaler_X = MinMaxScaler()\n",
        "scaler_y = MinMaxScaler()\n",
        "\n",
        "# Normalize the features (X) and target (y)\n",
        "X_scaled = scaler_X.fit_transform(X_cleaned)\n",
        "y_scaled = scaler_y.fit_transform(y_cleaned.values.reshape(-1, 1))\n",
        "\n",
        "# Print the shapes of the resulting scaled data\n",
        "print(\"Shape of X_scaled:\", X_scaled.shape)\n",
        "print(\"Shape of y_scaled:\", y_scaled.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eae83453"
      },
      "source": [
        "**Reasoning**:\n",
        "The error \"could not convert string to float: 'up'\" indicates that the `price_trend` column, which contains string values ('up' or 'down'), is still present in the `X_cleaned` DataFrame (features) when attempting to normalize it. The features should only contain numerical technical indicators. I need to exclude the `price_trend` column from the features DataFrame before normalization.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMxv6AzgD85E"
      },
      "source": [
        "# Identify technical indicator columns (excluding 'price_trend')\n",
        "original_cols = ['Open', 'High', 'Low', 'Close', 'Volume', 'Dividends', 'Stock Splits']\n",
        "technical_indicator_cols = [col for col in aapl_data.columns if col not in original_cols and col != 'price_trend']\n",
        "\n",
        "# Create feature DataFrame (X) and target Series (y)\n",
        "X = aapl_data[technical_indicator_cols].copy()\n",
        "y = aapl_data['Close'].copy()\n",
        "\n",
        "# Fill NaN values using forward fill\n",
        "X.fillna(method='ffill', inplace=True)\n",
        "y.fillna(method='ffill', inplace=True)\n",
        "\n",
        "# Now, drop any remaining NaNs that couldn't be forward-filled (e.g., NaNs at the very beginning)\n",
        "combined_df = pd.concat([X, y], axis=1).dropna()\n",
        "\n",
        "# Separate the combined DataFrame back into X and y\n",
        "X_cleaned = combined_df[technical_indicator_cols]\n",
        "y_cleaned = combined_df['Close']\n",
        "\n",
        "# Initialize the MinMaxScaler\n",
        "scaler_X = MinMaxScaler()\n",
        "scaler_y = MinMaxScaler()\n",
        "\n",
        "# Normalize the features (X) and target (y)\n",
        "X_scaled = scaler_X.fit_transform(X_cleaned)\n",
        "y_scaled = scaler_y.fit_transform(y_cleaned.values.reshape(-1, 1))\n",
        "\n",
        "# Print the shapes of the resulting scaled data\n",
        "print(\"Shape of X_scaled:\", X_scaled.shape)\n",
        "print(\"Shape of y_scaled:\", y_scaled.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9958738a"
      },
      "source": [
        "## Split data\n",
        "\n",
        "### Subtask:\n",
        "Split the data into training and testing sets. It's important to split the data chronologically to simulate a real-world scenario for out-of-sample testing.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6398e76a"
      },
      "source": [
        "**Reasoning**:\n",
        "Split the scaled data chronologically into training and testing sets and print their shapes to verify the split.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ccd0b214"
      },
      "source": [
        "# Determine the size of the training set (e.g., 80%)\n",
        "train_size = int(len(X_scaled) * 0.8)\n",
        "\n",
        "# Calculate the index to split the data\n",
        "split_index = train_size\n",
        "\n",
        "# Split the data into training and testing sets chronologically\n",
        "X_train, X_test = X_scaled[:split_index], X_scaled[split_index:]\n",
        "y_train, y_test = y_scaled[:split_index], y_scaled[split_index:]\n",
        "\n",
        "# Print the shapes of the training and testing sets\n",
        "print(\"Shape of X_train:\", X_train.shape)\n",
        "print(\"Shape of X_test:\", X_test.shape)\n",
        "print(\"Shape of y_train:\", y_train.shape)\n",
        "print(\"Shape of y_test:\", y_test.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "86655b2e"
      },
      "source": [
        "## Build and train regression model\n",
        "\n",
        "### Subtask:\n",
        "Define and train a regression model (e.g., a neural network suitable for time series or tabular data) using the prepared training data.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c3292ace"
      },
      "source": [
        "**Reasoning**:\n",
        "Import the necessary Keras layers and define a Sequential model with Dense layers for regression, then compile and train the model.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fe8c3d50"
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "\n",
        "# Define the regression model\n",
        "model_regression = Sequential([\n",
        "    Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
        "    Dropout(0.3),\n",
        "    Dense(64, activation='relu'),\n",
        "    Dense(1) # Output layer for regression\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model_regression.compile(optimizer='adam', loss='mse')\n",
        "\n",
        "# Print the model summary\n",
        "model_regression.summary()\n",
        "\n",
        "# Train the model\n",
        "history_regression = model_regression.fit(X_train, y_train, epochs=100, batch_size=32, validation_split=0.2, verbose=0)\n",
        "\n",
        "print(\"Model training complete.\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ffc7f1c7"
      },
      "source": [
        "## Evaluate model (in-sample)\n",
        "\n",
        "### Subtask:\n",
        "Evaluate the trained model's performance on the training data using appropriate regression metrics.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfa38930"
      },
      "source": [
        "**Reasoning**:\n",
        "Make predictions on the training data and calculate the in-sample evaluation metrics (R2, MAE, MAPE) to assess the model's performance on the data it was trained on.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0446f721"
      },
      "source": [
        "from sklearn.metrics import r2_score, mean_absolute_error, mean_absolute_percentage_error\n",
        "\n",
        "# Make predictions on the training data\n",
        "predictions_train = model_regression.predict(X_train)\n",
        "\n",
        "# Calculate R2 score for in-sample data\n",
        "r2_train = r2_score(y_train, predictions_train)\n",
        "\n",
        "# Calculate Mean Absolute Error (MAE) for in-sample data\n",
        "mae_train = mean_absolute_error(y_train, predictions_train)\n",
        "\n",
        "# Calculate Mean Absolute Percentage Error (MAPE) for in-sample data\n",
        "# Add a small epsilon to avoid division by zero in MAPE calculation if y_train has zero values\n",
        "epsilon = 1e-8\n",
        "mape_train = np.mean(np.abs((y_train - predictions_train) / (y_train + epsilon))) * 100\n",
        "\n",
        "\n",
        "# Print the in-sample evaluation metrics\n",
        "print(\"In-sample Evaluation Metrics:\")\n",
        "print(f'R2 Score: {r2_train}')\n",
        "print(f'Mean Absolute Error (MAE): {mae_train}')\n",
        "print(f'Mean Absolute Percentage Error (MAPE): {mape_train}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "183d28d9"
      },
      "source": [
        "**Reasoning**:\n",
        "Evaluate the trained regression model's performance on the testing data using appropriate regression metrics (R2, MAE, MAPE) to simulate out-of-sample performance, and then finish the task.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d276c1a7"
      },
      "source": [
        "# Make predictions on the testing data (out-of-sample)\n",
        "predictions_test = model_regression.predict(X_test)\n",
        "\n",
        "# Calculate R2 score for out-of-sample data\n",
        "r2_test = r2_score(y_test, predictions_test)\n",
        "\n",
        "# Calculate Mean Absolute Error (MAE) for out-of-sample data\n",
        "mae_test = mean_absolute_error(y_test, predictions_test)\n",
        "\n",
        "# Calculate Mean Absolute Percentage Error (MAPE) for out-of-sample data\n",
        "# Add a small epsilon to avoid division by zero in MAPE calculation if y_test has zero values\n",
        "mape_test = np.mean(np.abs((y_test - predictions_test) / (y_test + epsilon))) * 100\n",
        "\n",
        "# Print the out-of-sample evaluation metrics\n",
        "print(\"\\nOut-of-sample Evaluation Metrics:\")\n",
        "print(f'R2 Score: {r2_test}')\n",
        "print(f'Mean Absolute Error (MAE): {mae_test}')\n",
        "print(f'Mean Absolute Percentage Error (MAPE): {mape_test}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bfd5d59"
      },
      "source": [
        "## Unnormalize and report results\n",
        "\n",
        "### Subtask:\n",
        "Unnormalize the predictions and the test data to present the results in the original price scale. Report the performance metrics for both in-sample and out-of-sample evaluations, including MSE, MAE, and R2 score.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0893516e"
      },
      "source": [
        "**Reasoning**:\n",
        "Unnormalize the predictions and test data and then evaluate the model performance on both in-sample and out-of-sample data using R2, MAE, and MSE.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d230e527"
      },
      "source": [
        "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
        "\n",
        "# Unnormalize the in-sample predictions and actual values\n",
        "unnormalized_predictions_train = scaler_y.inverse_transform(predictions_train)\n",
        "unnormalized_y_train = scaler_y.inverse_transform(y_train)\n",
        "\n",
        "# Unnormalize the out-of-sample predictions and actual values\n",
        "unnormalized_predictions_test = scaler_y.inverse_transform(predictions_test)\n",
        "unnormalized_y_test = scaler_y.inverse_transform(y_test)\n",
        "\n",
        "# Calculate R2 score for unnormalized in-sample data\n",
        "r2_train_unnormalized = r2_score(unnormalized_y_train, unnormalized_predictions_train)\n",
        "\n",
        "# Calculate Mean Absolute Error (MAE) for unnormalized in-sample data\n",
        "mae_train_unnormalized = mean_absolute_error(unnormalized_y_train, unnormalized_predictions_train)\n",
        "\n",
        "# Calculate Mean Squared Error (MSE) for unnormalized in-sample data\n",
        "mse_train_unnormalized = mean_squared_error(unnormalized_y_train, unnormalized_predictions_train)\n",
        "\n",
        "# Print the unnormalized in-sample evaluation metrics\n",
        "print(\"Unnormalized In-sample Evaluation Metrics:\")\n",
        "print(f'R2 Score: {r2_train_unnormalized}')\n",
        "print(f'Mean Absolute Error (MAE): {mae_train_unnormalized}')\n",
        "print(f'Mean Squared Error (MSE): {mse_train_unnormalized}')\n",
        "\n",
        "# Calculate R2 score for unnormalized out-of-sample data\n",
        "r2_test_unnormalized = r2_score(unnormalized_y_test, unnormalized_predictions_test)\n",
        "\n",
        "# Calculate Mean Absolute Error (MAE) for unnormalized out-of-sample data\n",
        "mae_test_unnormalized = mean_absolute_error(unnormalized_y_test, unnormalized_predictions_test)\n",
        "\n",
        "# Calculate Mean Squared Error (MSE) for unnormalized out-of-sample data\n",
        "mse_test_unnormalized = mean_squared_error(unnormalized_y_test, unnormalized_predictions_test)\n",
        "\n",
        "# Print the unnormalized out-of-sample evaluation metrics\n",
        "print(\"\\nUnnormalized Out-of-sample Evaluation Metrics:\")\n",
        "print(f'R2 Score: {r2_test_unnormalized}')\n",
        "print(f'Mean Absolute Error (MAE): {mae_test_unnormalized}')\n",
        "print(f'Mean Squared Error (MSE): {mse_test_unnormalized}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fb1a40b8"
      },
      "source": [
        "## Evaluate model (out-of-sample)\n",
        "\n",
        "### Subtask:\n",
        "Evaluate the trained model's performance on the unseen test data (out-of-sample) using the same regression metrics.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3fc72177"
      },
      "source": [
        "**Reasoning**:\n",
        "Evaluate the trained model's performance on the unseen test data (out-of-sample) using the same regression metrics.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5b886763"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "# Make predictions on the testing data\n",
        "predictions_test = (model.predict(X_test_lstm) > 0.5).astype(\"int32\")\n",
        "\n",
        "# Calculate evaluation metrics for out-of-sample data\n",
        "accuracy_test = accuracy_score(y_test_lstm_encoded, predictions_test)\n",
        "precision_test = precision_score(y_test_lstm_encoded, predictions_test)\n",
        "recall_test = recall_score(y_test_lstm_encoded, predictions_test)\n",
        "f1_test = f1_score(y_test_lstm_encoded, predictions_test)\n",
        "conf_matrix_test = confusion_matrix(y_test_lstm_encoded, predictions_test)\n",
        "\n",
        "# Print the out-of-sample evaluation metrics\n",
        "print(\"\\nOut-of-sample Evaluation Metrics:\")\n",
        "print(f'Accuracy: {accuracy_test}')\n",
        "print(f'Precision: {precision_test}')\n",
        "print(f'Recall: {recall_test}')\n",
        "print(f'F1 Score: {f1_test}')\n",
        "print(f'Confusion Matrix:\\n{conf_matrix_test}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8749b7c3"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   The in-sample evaluation metrics for the unnormalized data show an R2 score of 0.868, an MAE of \\$7.714, and an MSE of 132.687. This indicates the model fits the training data reasonably well.\n",
        "*   The out-of-sample evaluation metrics for the unnormalized data show a negative R2 score of -0.742, an MAE of \\$40.167, and an MSE of 1704.458. The negative R2 score suggests the model performs worse than simply predicting the mean of the target variable on the test set. The MAE and MSE values are significantly higher than the in-sample metrics, indicating poor generalization to unseen data.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "*   The significant drop in performance from in-sample (R2: 0.868) to out-of-sample (R2: -0.742) data, along with the negative R2 score, strongly suggests that the model is overfitting the training data.\n",
        "*   Further steps should focus on addressing overfitting by techniques such as regularization, using a simpler model, increasing the size of the training data (if possible), or exploring different feature sets or engineering approaches.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gz18MFsrSUIc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcee3c95"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# Initialize the LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "\n",
        "# Encode the string labels in y_train_lstm and y_test_lstm\n",
        "y_train_lstm_encoded = label_encoder.fit_transform(y_train_lstm)\n",
        "y_test_lstm_encoded = label_encoder.transform(y_test_lstm)\n",
        "\n",
        "# Train the model with the encoded target variable\n",
        "history = model.fit(X_train_lstm, y_train_lstm_encoded, epochs=50, batch_size=32, validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6fceb7a7"
      },
      "source": [
        "## Evaluate model (in-sample)\n",
        "\n",
        "### Subtask:\n",
        "Evaluate the trained model's performance on the training data using appropriate classification metrics."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "90d34bb7"
      },
      "source": [
        "**Reasoning**:\n",
        "Make predictions on the training data and calculate evaluation metrics (accuracy, precision, recall, F1-score, and confusion matrix) to assess the model's performance on the data it was trained on."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "758315ab"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "import numpy as np\n",
        "\n",
        "# Make predictions on the training data\n",
        "# The output of the model is a probability (due to sigmoid activation), so we need to convert it to binary predictions\n",
        "predictions_train = (model.predict(X_train_lstm) > 0.5).astype(\"int32\")\n",
        "\n",
        "# Calculate evaluation metrics for in-sample data\n",
        "accuracy_train = accuracy_score(y_train_lstm_encoded, predictions_train)\n",
        "precision_train = precision_score(y_train_lstm_encoded, predictions_train)\n",
        "recall_train = recall_score(y_train_lstm_encoded, predictions_train)\n",
        "f1_train = f1_score(y_train_lstm_encoded, predictions_train)\n",
        "conf_matrix_train = confusion_matrix(y_train_lstm_encoded, predictions_train)\n",
        "\n",
        "# Print the in-sample evaluation metrics\n",
        "print(\"In-sample Evaluation Metrics:\")\n",
        "print(f'Accuracy: {accuracy_train}')\n",
        "print(f'Precision: {precision_train}')\n",
        "print(f'Recall: {recall_train}')\n",
        "print(f'F1 Score: {f1_train}')\n",
        "print(f'Confusion Matrix:\\n{conf_matrix_train}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a91cf38f"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   **In-sample Evaluation:**\n",
        "    *   Accuracy: {accuracy_train:.4f}\n",
        "    *   Precision: {precision_train:.4f}\n",
        "    *   Recall: {recall_train:.4f}\n",
        "    *   F1 Score: {f1_train:.4f}\n",
        "    *   Confusion Matrix:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "795a7a2a"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "*   **In-sample Evaluation:**\n",
        "    *   Accuracy: {accuracy_train:.4f}\n",
        "    *   Precision: {precision_train:.4f}\n",
        "    *   Recall: {recall_train:.4f}\n",
        "    *   F1 Score: {f1_train:.4f}\n",
        "    *   Confusion Matrix:\n",
        "*   **Out-of-sample Evaluation:**\n",
        "    *   Accuracy: {accuracy_test:.4f}\n",
        "    *   Precision: {precision_test:.4f}\n",
        "    *   Recall: {recall_test:.4f}\n",
        "    *   F1 Score: {f1_test:.4f}\n",
        "    *   Confusion Matrix:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b810095d"
      },
      "source": [
        "## Unnormalize and report results\n",
        "\n",
        "### Subtask:\n",
        "Unnormalize the predictions and the test data to present the results in the original price scale. Report the performance metrics for both in-sample and out-of-sample evaluations, including MSE, MAE, and R2 score."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "75a058c3"
      },
      "source": [
        "**Reasoning**:\n",
        "Unnormalize the predictions and test data and then evaluate the model performance on both in-sample and out-of-sample data using R2, MAE, and MSE."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cde653af"
      },
      "source": [
        "from sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error\n",
        "\n",
        "# Unnormalize the in-sample predictions and actual values\n",
        "unnormalized_predictions_train = scaler_y.inverse_transform(predictions_train)\n",
        "unnormalized_y_train = scaler_y.inverse_transform(y_train)\n",
        "\n",
        "# Unnormalize the out-of-sample predictions and actual values\n",
        "unnormalized_predictions_test = scaler_y.inverse_transform(predictions_test)\n",
        "unnormalized_y_test = scaler_y.inverse_transform(y_test)\n",
        "\n",
        "# Calculate R2 score for unnormalized in-sample data\n",
        "r2_train_unnormalized = r2_score(unnormalized_y_train, unnormalized_predictions_train)\n",
        "\n",
        "# Calculate Mean Absolute Error (MAE) for unnormalized in-sample data\n",
        "mae_train_unnormalized = mean_absolute_error(unnormalized_y_train, unnormalized_predictions_train)\n",
        "\n",
        "# Calculate Mean Squared Error (MSE) for unnormalized in-sample data\n",
        "mse_train_unnormalized = mean_squared_error(unnormalized_y_train, unnormalized_predictions_train)\n",
        "\n",
        "# Print the unnormalized in-sample evaluation metrics\n",
        "print(\"Unnormalized In-sample Evaluation Metrics:\")\n",
        "print(f'R2 Score: {r2_train_unnormalized}')\n",
        "print(f'Mean Absolute Error (MAE): {mae_train_unnormalized}')\n",
        "print(f'Mean Squared Error (MSE): {mse_train_unnormalized}')\n",
        "\n",
        "# Calculate R2 score for unnormalized out-of-sample data\n",
        "r2_test_unnormalized = r2_score(unnormalized_y_test, unnormalized_predictions_test)\n",
        "\n",
        "# Calculate Mean Absolute Error (MAE) for unnormalized out-of-sample data\n",
        "mae_test_unnormalized = mean_absolute_error(unnormalized_y_test, unnormalized_predictions_test)\n",
        "\n",
        "# Calculate Mean Squared Error (MSE) for unnormalized out-of-sample data\n",
        "mse_test_unnormalized = mean_squared_error(unnormalized_y_test, unnormalized_predictions_test)\n",
        "\n",
        "# Print the unnormalized out-of-sample evaluation metrics\n",
        "print(\"\\nUnnormalized Out-of-sample Evaluation Metrics:\")\n",
        "print(f'R2 Score: {r2_test_unnormalized}')\n",
        "print(f'Mean Absolute Error (MAE): {mae_test_unnormalized}')\n",
        "print(f'Mean Squared Error (MSE): {mse_test_unnormalized}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0b1983a"
      },
      "source": [
        "## Finish task\n",
        "\n",
        "### Subtask:\n",
        "Summarize the findings and conclude the analysis."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7b2d7b14"
      },
      "source": [
        "## Summary:\n",
        "\n",
        "### Data Analysis Key Findings\n",
        "\n",
        "* The in-sample evaluation metrics for the unnormalized data show an R2 score of {r2_train_unnormalized:.3f}, an MAE of ${mae_train_unnormalized:.3f}, and an MSE of {mse_train_unnormalized:.3f}. This indicates the model fits the training data reasonably well.\n",
        "* The out-of-sample evaluation metrics for the unnormalized data show an R2 score of {r2_test_unnormalized:.3f}, an MAE of ${mae_test_unnormalized:.3f}, and an MSE of {mse_test_unnormalized:.3f}. The negative R2 score suggests the model performs worse than simply predicting the mean of the target variable on the test set. The MAE and MSE values are significantly higher than the in-sample metrics, indicating poor generalization to unseen data.\n",
        "\n",
        "### Insights or Next Steps\n",
        "\n",
        "* The significant drop in performance from in-sample (R2: {r2_train_unnormalized:.3f}) to out-of-sample (R2: {r2_test_unnormalized:.3f}) data, along with the negative R2 score, strongly suggests that the model is overfitting the training data.\n",
        "* Further steps should focus on addressing overfitting by techniques such as regularization, using a simpler model, increasing the size of the training data (if possible), or exploring different feature sets or engineering approaches."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d3fd795d"
      },
      "source": [
        "### compare predictions to y_test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ff0c355e",
        "outputId": "bffef96e-6afa-49e1-88c6-2f8bc93afbf4"
      },
      "source": [
        "# compare predictions to y_test\n",
        "print(predictions_cnn[:10])\n",
        "print(y_test_cnn[:10])"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1.5200916e-01]\n",
            " [7.2387382e-02]\n",
            " [3.0074019e-02]\n",
            " [1.3163438e-01]\n",
            " [7.1325665e-04]\n",
            " [2.2862561e-02]\n",
            " [7.2477549e-01]\n",
            " [5.7211071e-01]\n",
            " [5.0551713e-01]\n",
            " [1.5211206e-02]]\n",
            "[[0.15634065]\n",
            " [0.07597869]\n",
            " [0.0341382 ]\n",
            " [0.13259221]\n",
            " [0.00115011]\n",
            " [0.02429969]\n",
            " [0.72723629]\n",
            " [0.57550629]\n",
            " [0.51266409]\n",
            " [0.01617873]]\n"
          ]
        }
      ]
    }
  ]
}